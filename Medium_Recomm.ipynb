{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Unzipping help/tagsets.zip.\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/treebank.zip.\n"
     ]
    }
   ],
   "source": [
    "# libraries to display dataframe and images\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "# matplotlib for vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# inbuild library to work with textual data\n",
    "import string\n",
    "# Setting up the NLTK to pre-processing textual data\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('treebank')\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "pd.set_option(\"display.max_columns\", 100)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>Understanding the key concepts of ensemble lea...</td>\n",
       "      <td>Joseph Rocca</td>\n",
       "      <td>20</td>\n",
       "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://towardsdatascience.com/understanding-a...</td>\n",
       "      <td>Understanding AUC - ROC Curve</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>Sarang Narkhede</td>\n",
       "      <td>5</td>\n",
       "      <td>In Machine Learning, performance measurement i...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://towardsdatascience.com/how-to-work-wit...</td>\n",
       "      <td>How to work with object detection datasets in ...</td>\n",
       "      <td>A comprehensive guide to defining, loading, ex...</td>\n",
       "      <td>Eric Hofesmann</td>\n",
       "      <td>10</td>\n",
       "      <td>Microsoft's Common Objects in Context dataset ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://towardsdatascience.com/11-dimensionali...</td>\n",
       "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
       "      <td>Reduce the size of your dataset while keeping ...</td>\n",
       "      <td>Rukshan Pramoditha</td>\n",
       "      <td>16</td>\n",
       "      <td>In both Statistics and Machine Learning, the n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://towardsdatascience.com/the-time-series...</td>\n",
       "      <td>The Time Series Transformer</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>Theodoros Ntakouris</td>\n",
       "      <td>6</td>\n",
       "      <td>Attention Is All You Need they said. Is it a m...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://netflixtechblog.com/learning-a-persona...</td>\n",
       "      <td>Learning a Personalized Homepage</td>\n",
       "      <td>how to best tailor each member's homepage to m...</td>\n",
       "      <td>Netflix Technology Blog</td>\n",
       "      <td>15</td>\n",
       "      <td>by Chris Alvino and Justin Basilico\\nAs we've ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://towardsdatascience.com/6-data-science-...</td>\n",
       "      <td>6 Data Science Certificates To Level Up Your C...</td>\n",
       "      <td>Pump up your portfolio and get closer to your ...</td>\n",
       "      <td>Sara A. Metwalli</td>\n",
       "      <td>6</td>\n",
       "      <td>Because of the appeal of the field of data sci...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://towardsdatascience.com/transformers-ex...</td>\n",
       "      <td>Transformers Explained Visually (Part 2): How ...</td>\n",
       "      <td>A Gentle Guide to the Transformer under the ho...</td>\n",
       "      <td>Ketan Doshi</td>\n",
       "      <td>11</td>\n",
       "      <td>This is the second article in my series on Tra...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://medium.com/coders-camp/60-python-proje...</td>\n",
       "      <td>60 Python Projects with Source Code</td>\n",
       "      <td>60 Python Projects with Source code solved and...</td>\n",
       "      <td>Aman Kharwal</td>\n",
       "      <td>2</td>\n",
       "      <td>Python has been in the top 10 popular programm...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://towardsdatascience.com/geometric-found...</td>\n",
       "      <td>Geometric foundations of Deep Learning</td>\n",
       "      <td>Geometric Deep Learning is an attempt to unify...</td>\n",
       "      <td>Michael Bronstein</td>\n",
       "      <td>13</td>\n",
       "      <td>This blog post was co-authored with Joan Bruna...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link  \\\n",
       "0  https://towardsdatascience.com/ensemble-method...   \n",
       "1  https://towardsdatascience.com/understanding-a...   \n",
       "2  https://towardsdatascience.com/how-to-work-wit...   \n",
       "3  https://towardsdatascience.com/11-dimensionali...   \n",
       "4  https://towardsdatascience.com/the-time-series...   \n",
       "5  https://netflixtechblog.com/learning-a-persona...   \n",
       "6  https://towardsdatascience.com/6-data-science-...   \n",
       "7  https://towardsdatascience.com/transformers-ex...   \n",
       "8  https://medium.com/coders-camp/60-python-proje...   \n",
       "9  https://towardsdatascience.com/geometric-found...   \n",
       "\n",
       "                                               title  \\\n",
       "0   Ensemble methods: bagging, boosting and stacking   \n",
       "1                      Understanding AUC - ROC Curve   \n",
       "2  How to work with object detection datasets in ...   \n",
       "3  11 Dimensionality reduction techniques you sho...   \n",
       "4                        The Time Series Transformer   \n",
       "5                   Learning a Personalized Homepage   \n",
       "6  6 Data Science Certificates To Level Up Your C...   \n",
       "7  Transformers Explained Visually (Part 2): How ...   \n",
       "8                60 Python Projects with Source Code   \n",
       "9             Geometric foundations of Deep Learning   \n",
       "\n",
       "                                           sub_title                   author  \\\n",
       "0  Understanding the key concepts of ensemble lea...             Joseph Rocca   \n",
       "1  In Machine Learning, performance measurement i...          Sarang Narkhede   \n",
       "2  A comprehensive guide to defining, loading, ex...           Eric Hofesmann   \n",
       "3  Reduce the size of your dataset while keeping ...       Rukshan Pramoditha   \n",
       "4  Attention Is All You Need they said. Is it a m...      Theodoros Ntakouris   \n",
       "5  how to best tailor each member's homepage to m...  Netflix Technology Blog   \n",
       "6  Pump up your portfolio and get closer to your ...         Sara A. Metwalli   \n",
       "7  A Gentle Guide to the Transformer under the ho...              Ketan Doshi   \n",
       "8  60 Python Projects with Source code solved and...             Aman Kharwal   \n",
       "9  Geometric Deep Learning is an attempt to unify...        Michael Bronstein   \n",
       "\n",
       "   reading_time                                               text  id  \n",
       "0            20  This post was co-written with Baptiste Rocca.\\...   1  \n",
       "1             5  In Machine Learning, performance measurement i...   2  \n",
       "2            10  Microsoft's Common Objects in Context dataset ...   3  \n",
       "3            16  In both Statistics and Machine Learning, the n...   4  \n",
       "4             6  Attention Is All You Need they said. Is it a m...   5  \n",
       "5            15  by Chris Alvino and Justin Basilico\\nAs we've ...   6  \n",
       "6             6  Because of the appeal of the field of data sci...   7  \n",
       "7            11  This is the second article in my series on Tra...   8  \n",
       "8             2  Python has been in the top 10 popular programm...   9  \n",
       "9            13  This blog post was co-authored with Joan Bruna...  10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataframe : (208, 7)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "spacy.load('en_core_web_sm')\n",
    "from spacy import displacy\n",
    "\n",
    "# reading the csv data file\n",
    "articles = pd.read_csv(\"medium_articles_v3.csv\")\n",
    "display(articles.head(10))\n",
    "print(\"Shape of dataframe : {}\".format(articles.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'author': 'Sarang Narkhede',\n",
      " 'id': 2,\n",
      " 'link': 'https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5?source=tag_archive---------1-----------------------',\n",
      " 'reading_time': 5,\n",
      " 'sub_title': 'In Machine Learning, performance measurement is an essential '\n",
      "              'task. So when it comes to a classification problem, we can '\n",
      "              'count on an AUC - ROC Curve. When we need to check or visualize '\n",
      "              'the performance...',\n",
      " 'text': 'In Machine Learning, performance measurement is an essential task. '\n",
      "         'So when it comes to a classification problem, we can count on an AUC '\n",
      "         '- ROC Curve. When we need to check or visualize the performance of '\n",
      "         'the multi-class classification problem, we use the AUC (Area Under '\n",
      "         'The Curve) ROC (Receiver Operating Characteristics) curve. It is one '\n",
      "         'of the most important evaluation metrics for checking any '\n",
      "         \"classification model's performance. It is also written as AUROC \"\n",
      "         '(Area Under the Receiver Operating Characteristics)\\n'\n",
      "         'Note: For better understanding, I suggest you read my article about '\n",
      "         'Confusion Matrix.\\n'\n",
      "         'This blog aims to answer the following questions:\\n'\n",
      "         '1. What is the AUC - ROC Curve?\\n'\n",
      "         '2. Defining terms used in AUC and ROC Curve.\\n'\n",
      "         '3. How to speculate the performance of the model?\\n'\n",
      "         '4. Relation between Sensitivity, Specificity, FPR, and Threshold.\\n'\n",
      "         '5. How to use AUC - ROC curve for the multiclass model?\\n'\n",
      "         'AUC - ROC curve is a performance measurement for the classification '\n",
      "         'problems at various threshold settings. ROC is a probability curve '\n",
      "         'and AUC represents the degree or measure of separability. It tells '\n",
      "         'how much the model is capable of distinguishing between classes. '\n",
      "         'Higher the AUC, the better the model is at predicting 0 classes as 0 '\n",
      "         'and 1 classes as 1. By analogy, the Higher the AUC, the better the '\n",
      "         'model is at distinguishing between patients with the disease and no '\n",
      "         'disease.\\n'\n",
      "         'The ROC curve is plotted with TPR against the FPR where TPR is on '\n",
      "         'the y-axis and FPR is on the x-axis.\\n'\n",
      "         'An excellent model has AUC near to the 1 which means it has a good '\n",
      "         'measure of separability. A poor model has an AUC near 0 which means '\n",
      "         'it has the worst measure of separability. In fact, it means it is '\n",
      "         'reciprocating the result. It is predicting 0s as 1s and 1s as 0s. '\n",
      "         'And when AUC is 0.5, it means the model has no class separation '\n",
      "         'capacity whatsoever.\\n'\n",
      "         \"Let's interpret the above statements.\\n\"\n",
      "         \"As we know, ROC is a curve of probability. So let's plot the \"\n",
      "         'distributions of those probabilities:\\n'\n",
      "         'Note: Red distribution curve is of the positive class (patients with '\n",
      "         'disease) and the green distribution curve is of the negative '\n",
      "         'class(patients with no disease).\\n'\n",
      "         \"This is an ideal situation. When two curves don't overlap at all \"\n",
      "         'means model has an ideal measure of separability. It is perfectly '\n",
      "         'able to distinguish between positive class and negative class.\\n'\n",
      "         'When two distributions overlap, we introduce type 1 and type 2 '\n",
      "         'errors. Depending upon the threshold, we can minimize or maximize '\n",
      "         'them. When AUC is 0.7, it means there is a 70% chance that the model '\n",
      "         'will be able to distinguish between positive class and negative '\n",
      "         'class.\\n'\n",
      "         'This is the worst situation. When AUC is approximately 0.5, the '\n",
      "         'model has no discrimination capacity to distinguish between positive '\n",
      "         'class and negative class.\\n'\n",
      "         'When AUC is approximately 0, the model is actually reciprocating the '\n",
      "         'classes. It means the model is predicting a negative class as a '\n",
      "         'positive class and vice versa.\\n'\n",
      "         'Sensitivity and Specificity are inversely proportional to each '\n",
      "         'other. So when we increase Sensitivity, Specificity decreases, and '\n",
      "         'vice versa.\\n'\n",
      "         'Sensitivity, Specificity and Sensitivity, Specificity\\n'\n",
      "         'When we decrease the threshold, we get more positive values thus it '\n",
      "         'increases the sensitivity and decreasing the specificity.\\n'\n",
      "         'Similarly, when we increase the threshold, we get more negative '\n",
      "         'values thus we get higher specificity and lower sensitivity.\\n'\n",
      "         'As we know FPR is 1 - specificity. So when we increase TPR, FPR also '\n",
      "         'increases and vice versa.\\n'\n",
      "         'TPR, FPR and TPR, FPR\\n'\n",
      "         'In a multi-class model, we can plot the N number of AUC ROC Curves '\n",
      "         'for N number classes using the One vs ALL methodology. So for '\n",
      "         'example, If you have three classes named X, Y, and Z, you will have '\n",
      "         'one ROC for X classified against Y and Z, another ROC for Y '\n",
      "         'classified against X and Z, and the third one of Z classified '\n",
      "         'against Y and X.\\n'\n",
      "         'Thanks for Reading.\\n'\n",
      "         \"I hope I've given you some understanding of what exactly is the AUC \"\n",
      "         '- ROC Curve. If you like this post, a tad of extra motivation will '\n",
      "         'be helpful by giving this post some claps . I am always open to your '\n",
      "         'questions and suggestions. You can share this on Facebook, Twitter, '\n",
      "         'Linkedin, so someone in need might stumble upon this.\\n'\n",
      "         'You can reach me at:\\n'\n",
      "         'LinkedIn: https://www.linkedin.com/in/narkhedesarang/\\n'\n",
      "         'Twitter: https://twitter.com/narkhede_sarang\\n'\n",
      "         'Github: https://github.com/TheSarang\\n',\n",
      " 'title': 'Understanding AUC - ROC Curve'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(articles.iloc[1].to_dict(), compact=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 208 entries, 0 to 207\n",
      "Data columns (total 7 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   link          208 non-null    object\n",
      " 1   title         208 non-null    object\n",
      " 2   sub_title     208 non-null    object\n",
      " 3   author        208 non-null    object\n",
      " 4   reading_time  208 non-null    int64 \n",
      " 5   text          208 non-null    object\n",
      " 6   id            208 non-null    int64 \n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 11.5+ KB\n"
     ]
    }
   ],
   "source": [
    "articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>title</th>\n",
       "      <th>sub_title</th>\n",
       "      <th>author</th>\n",
       "      <th>reading_time</th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>208.000000</td>\n",
       "      <td>208</td>\n",
       "      <td>208.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>208</td>\n",
       "      <td>208</td>\n",
       "      <td>204</td>\n",
       "      <td>179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>208</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>https://towardsdatascience.com/ensemble-method...</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>Update: This article is part of a series. Chec...</td>\n",
       "      <td>Adam Geitgey</td>\n",
       "      <td>NaN</td>\n",
       "      <td>This post was co-written with Baptiste Rocca.\\...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.375000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.091346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.880224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.575453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>107.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>162.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>214.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     link  \\\n",
       "count                                                 208   \n",
       "unique                                                208   \n",
       "top     https://towardsdatascience.com/ensemble-method...   \n",
       "freq                                                    1   \n",
       "mean                                                  NaN   \n",
       "std                                                   NaN   \n",
       "min                                                   NaN   \n",
       "25%                                                   NaN   \n",
       "50%                                                   NaN   \n",
       "75%                                                   NaN   \n",
       "max                                                   NaN   \n",
       "\n",
       "                                                   title  \\\n",
       "count                                                208   \n",
       "unique                                               208   \n",
       "top     Ensemble methods: bagging, boosting and stacking   \n",
       "freq                                                   1   \n",
       "mean                                                 NaN   \n",
       "std                                                  NaN   \n",
       "min                                                  NaN   \n",
       "25%                                                  NaN   \n",
       "50%                                                  NaN   \n",
       "75%                                                  NaN   \n",
       "max                                                  NaN   \n",
       "\n",
       "                                                sub_title        author  \\\n",
       "count                                                 208           208   \n",
       "unique                                                204           179   \n",
       "top     Update: This article is part of a series. Chec...  Adam Geitgey   \n",
       "freq                                                    4             5   \n",
       "mean                                                  NaN           NaN   \n",
       "std                                                   NaN           NaN   \n",
       "min                                                   NaN           NaN   \n",
       "25%                                                   NaN           NaN   \n",
       "50%                                                   NaN           NaN   \n",
       "75%                                                   NaN           NaN   \n",
       "max                                                   NaN           NaN   \n",
       "\n",
       "        reading_time                                               text  \\\n",
       "count     208.000000                                                208   \n",
       "unique           NaN                                                208   \n",
       "top              NaN  This post was co-written with Baptiste Rocca.\\...   \n",
       "freq             NaN                                                  1   \n",
       "mean       12.375000                                                NaN   \n",
       "std        13.880224                                                NaN   \n",
       "min         2.000000                                                NaN   \n",
       "25%         6.000000                                                NaN   \n",
       "50%         9.000000                                                NaN   \n",
       "75%        13.000000                                                NaN   \n",
       "max       149.000000                                                NaN   \n",
       "\n",
       "                id  \n",
       "count   208.000000  \n",
       "unique         NaN  \n",
       "top            NaN  \n",
       "freq           NaN  \n",
       "mean    107.091346  \n",
       "std      62.575453  \n",
       "min       1.000000  \n",
       "25%      52.750000  \n",
       "50%     107.500000  \n",
       "75%     162.250000  \n",
       "max     214.000000  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leenasingh/anaconda3/lib/python3.11/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.\n",
      "  with pd.option_context('mode.use_inf_as_na', True):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x17679efd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAHkCAYAAADvrlz5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2bUlEQVR4nO3de3RU9bnG8WfPDIEEEg0xIYJVMDSAGAKWILYIGBeltdg2Ug9eQrnVEuHAoUCDXNRYqkKL3KSYAqnQgwhqUkRbW1GpWBtdQNWq3AQDViEGYyCGS5KZ2ecPDqPjhDC5wP4NfD9rZWHevWfmfWfiPNm/mdmxbNu2BQAAHOVyugEAAEAgAwBgBAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAzgcboBJ/h8fn3++dGw93e5LLVt21qff35Ufn/kn9jsfJqHWczELGZiFmckJsaGtR9HyGFwuSxZliWXy3K6lWZxPs3DLGZiFjMxi9kIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAj9MNQPJblo5Ve0PqMS09ctm2Ax0BAM41AtkAx6q9WvrMOyH1cT9JV5sotwMdAQDONZasAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAAfA75HDrdCUAAACCQz6HTnQAkZ2i6A90AAEzCkjUAAAYgkAEAMIBRgVxSUqJevXqpqKgoUNuxY4eys7PVs2dPDRw4UAUFBQ52CADA2WFMINfW1mrq1Kk6duxYoFZRUaFRo0apY8eOKiws1IQJE7Ro0SIVFhY62CkAAM3PmDd1Pfroo2rdunVQ7amnnlJUVJTy8vLk8XiUkpKi/fv3a/ny5Ro6dKhDnQIA0PyMOELesmWL1q1bp7lz5wbVt27dqoyMDHk8X/7e0LdvX5WUlKi8vPxctwkAwFnjeCBXVlYqNzdXs2bN0qWXXhq0rbS0VMnJyUG1pKQkSdKBAwfOWY8AAJxtji9Z5+XlqWfPnrr55ptDtp04cUJRUVFBtZYtW0qSqqurm3S7Hk/4v4u43a6gfxvLqvXLsqy6t9VRtyyrQX2Gq7nmMQGzmIlZzMQsZnM0kNevX6+tW7fqueeeq3N7q1atVFNTE1Q7FcQxMTGNvl2Xy1J8fOsz7/g1cXHRjb5NSTpaWyWPxx1StyzVWfd43I3qM1xNncckzGImZjETs5jJ0UAuLCxUeXm5Bg4cGFS///77VVBQoPbt26usrCxo26nv27Vr1+jb9fttVVYeO/OO/8/tdikuLlqVlcfl8/kbfbter09ery+kbtuqs+71+lRRcbTRt3c6zTWPCZjFTMxiJmZxRrgHVo4G8rx583TixImg2ne/+11NnDhRN910k/785z9r7dq18vl8crtPHkEWFxerU6dOSkhIaNJte70NfwB9Pn+jLneKbduybfu02+qqNeX2zqSp85iEWczELGZiFjM5uvjerl07XXHFFUFfkpSQkKAOHTpo6NChqqqq0syZM7Vnzx4VFRVp1apVGjt2rJNtAwDQ7Ix+NTwhIUErVqxQSUmJsrKytGTJEuXm5iorK8vp1gAAaFaOv8v663bt2hX0fY8ePbRu3TqHugEA4Nww+ggZAIALBYEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAAHqcbOB/5LUvHqr1OtwEAiCAE8llwrNqrpc+8E1LPGZruQDcAgEjAkjUAAAYgkAEAMIDjS9bl5eWaM2eOXnvtNVVXVysjI0O5ubnq3LmzJGn69OkqKioKuky7du20efNmJ9oFAOCscDyQ7777brlcLi1fvlwxMTFatGiRRo4cqY0bNyo6Olq7du1STk6OsrOzA5dxu90OdgwAQPNzdMm6oqJCl112mWbPnq20tDSlpKRo3LhxOnTokD744AP5fD7t2bNHaWlpSkxMDHy1bdvWybYBAGh2jh4hx8fHa/78+YHvP/vsMxUUFCg5OVmdO3fWvn37VF1drZSUFAe7BADg7HN8yfqUe++9V0899ZSioqL02GOPKSYmRrt375ZlWVq1apU2b94sl8ulAQMGaNKkSYqNjXW6ZQAAmo0xgTxixAgNGzZMTz75pMaPH681a9bogw8+kMvlUocOHZSfn6/9+/dr7ty52r17t1atWiWXq/Er7h5P+Jd1u11B/56JVeuXZVl1b2tA3bKsBvUZrobOYzJmMROzmIlZzGZMIJ96V/Xs2bP19ttva/Xq1XrooYc0cuRIxcXFSZJSU1OVmJioYcOG6d1331V6euNOtOFyWYqPb93gy8XFRYe139HaKnk8oW88syw1qO7xuBvVZ7jCnScSMIuZmMVMzGImRwO5vLxcxcXF+v73vx9457TL5VJKSorKyspkWVYgjE9JTU2VJJWWljY6kP1+W5WVx8Le3+12KS4uWpWVx+Xz+c+4v9frk9frC6nbthpU93p9qqg4Gnaf4WroPCZjFjMxi5mYxRnhHlg5GshlZWWaMmWKEhISdN1110mSamtrtX37dmVmZmrKlCk6fPiwCgoKApd59913JX15RN1YXm/DH0Cfzx/W5Wzblm3bp90Wbt227Ub1Ga5w54kEzGImZjETs5jJ0cX3rl27ql+/fnrggQe0detW7d69W9OmTVNlZaVGjhypIUOG6PXXX9djjz2mjz76SK+++qpmzJihIUOG8M5rAMB5xdEjZMuytHDhQj3yyCOaNGmSvvjiC/Xu3VtPPPGE2rdvr/bt22vRokXKz89Xfn6+YmNjdfPNN2vSpElOtg0AQLNz/E1dsbGxysvLU15eXp3bBw8erMGDB5/bpgAAOMfOn/eLAwAQwQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAMcDuby8XL/85S/Vt29f9erVSz//+c+1Z8+ewPYdO3YoOztbPXv21MCBA1VQUOBgtwAAnB2OB/Ldd9+t//znP1q+fLmeeeYZtWrVSiNHjtTx48dVUVGhUaNGqWPHjiosLNSECRO0aNEiFRYWOt02AADNyuPkjVdUVOiyyy7T3XffrW9+85uSpHHjxulHP/qRPvjgAxUXFysqKkp5eXnyeDxKSUnR/v37tXz5cg0dOtTJ1gEAaFaOHiHHx8dr/vz5gTD+7LPPVFBQoOTkZHXu3Flbt25VRkaGPJ4vf2/o27evSkpKVF5e7lTbAAA0O0ePkL/q3nvv1VNPPaWoqCg99thjiomJUWlpqVJTU4P2S0pKkiQdOHBACQkJTrQKAECzMyaQR4wYoWHDhunJJ5/U+PHjtWbNGp04cUJRUVFB+7Vs2VKSVF1d3aTb83jCXxxwu11B/56JVeuXZVl1b2tA3bKsBvUZrobOYzJmMROzmIlZzGZMIHfu3FmSNHv2bL399ttavXq1WrVqpZqamqD9TgVxTExMo2/L5bIUH9+6wZeLi4sOa7+jtVXyeNwhdctSg+oej7tRfYYr3HkiAbOYiVnMxCxmcjSQy8vLVVxcrO9///tyu08GksvlUkpKisrKypScnKyysrKgy5z6vl27do2+Xb/fVmXlsbD3d7tdiouLVmXlcfl8/jPu7/X65PX6Quq2rQbVvV6fKiqOht1nuBo6j8mYxUzMYiZmcUa4B1aOBnJZWZmmTJmihIQEXXfddZKk2tpabd++XZmZmbrkkku0du1a+Xy+QGAXFxerU6dOTX792Ott+APo8/nDupxt27Jt+7Tbwq3btt2oPsMV7jyRgFnMxCxmYhYzObr43rVrV/Xr108PPPCAtm7dqt27d2vatGmqrKzUyJEjNXToUFVVVWnmzJnas2ePioqKtGrVKo0dO9bJtgEAaHaOBrJlWVq4cKH69u2rSZMm6dZbb9WRI0f0xBNPqH379kpISNCKFStUUlKirKwsLVmyRLm5ucrKynKybQAAmp3jb+qKjY1VXl6e8vLy6tzeo0cPrVu37tw2BQDAOXb+vF8cAIAIRiADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABjA43QDhw8f1vz58/X3v/9dVVVV6tKli6ZMmaLevXtLkqZPn66ioqKgy7Rr106bN292ol0AAM4KxwN58uTJKi8v1/z589W2bVutWbNGY8aMUVFRkVJSUrRr1y7l5OQoOzs7cBm32+1gxwAAND9Hl6z379+v119/Xffff7969+6tK6+8UjNnzlS7du30/PPPy+fzac+ePUpLS1NiYmLgq23btk62DQBAs3M0kOPj47Vs2TJdffXVgZplWbJtW0eOHNG+fftUXV2tlJQUB7sEAODsc3TJOi4uTgMGDAiqvfDCC/roo4/Ur18/7d69W5ZladWqVdq8ebNcLpcGDBigSZMmKTY2tkm37fGE/7uI2+0K+vdMrFq/LMuqe1sD6pZlNajPcDV0HpMxi5mYxUzMYjbHX0P+qm3btmnGjBm68cYblZmZqcWLF8vlcqlDhw7Kz8/X/v37NXfuXO3evVurVq2Sy9W4B8LlshQf37rBl4uLiw5rv6O1VfJ4Ql/ntiw1qO7xuBvVZ7jCnScSMIuZmMVMzGImYwL5pZde0tSpU5Wenq758+dLkiZMmKCRI0cqLi5OkpSamqrExEQNGzZM7777rtLT0xt1W36/rcrKY2Hv73a7FBcXrcrK4/L5/Gfc3+v1yev1hdRtWw2qe70+VVQcDbvPcDV0HpMxi5mYxUzM4oxwD6yMCOTVq1frwQcf1KBBgzRv3jxFRUVJOrlkeyqMT0lNTZUklZaWNjqQJcnrbfgD6PP5w7qcbduybfu028Kt27bdqD7DFe48kYBZzMQsZmIWMzm++L5mzRrNnj1bd955pxYuXBgIY0maMmWKxowZE7T/u+++K0nq3LnzOe0TAICzydFALikp0UMPPaRBgwZp7NixKi8v16FDh3To0CF98cUXGjJkiF5//XU99thj+uijj/Tqq69qxowZGjJkCO+8BgCcVxxdsv7b3/6m2tpabdy4URs3bgzalpWVpTlz5mjRokXKz89Xfn6+YmNjdfPNN2vSpEnONAwAwFniaCDn5OQoJyen3n0GDx6swYMHn6OOAABwRqOWrLds2aKjR+t+929lZaX+/Oc/N6kpAAAuNI0K5J/+9Kfau3dvndu2b9+u6dOnN6kpAAAuNGEvWU+bNk0HDx6UdPLjOHl5eWrTpk3Ifvv27dMll1zSfB0CAHABCPsIefDgwSGfrz31/akvl8ulnj176uGHHz4rzQIAcL4K+wg5MzNTmZmZkqThw4crLy+Pjx4BANBMGvUu6//93/9t7j4AALigNSqQjx8/rvz8fG3atEnHjx+X3x982jLLsvTSSy81S4MAAFwIGhXIDz74oAoLC9WnTx9169at0X91CQAAnNSoQH7xxRf1i1/8Qj//+c+bux8AAC5IjTq09Xq96tGjR3P3AgDABatRgdyvXz9t3ry5uXsBAOCC1agl65tuukn333+/Pv/8c6Wnpys6Ojpknx//+MdN7Q0AgAtGowL51F9bWr9+vdavXx+y3bKsCyaQ/ZalY9Vep9sAAES4RgXyyy+/3Nx9RKxj1V4tfeadoFrO0HSHugEARKpGBXKHDh2auw8AAC5ojQrkJUuWnHGf//7v/27MVQMAcEFq9kBu06aNkpKSCGQAABqgUYG8c+fOkNqxY8e0bds25eXl6d57721yYwAAXEia7ZyXMTExuv766zV+/Hj95je/aa6rBQDggtDsJ6G+9NJLtXfv3ua+WgAAzmuNWrKui23bOnjwoJYvX867sAEAaKBGBXLXrl1lWVad22zbZskaAIAGalQgjx8/vs5AbtOmjQYOHKiOHTs2tS8AAC4ojQrkCRMmNHcfAABc0Br9GnJNTY2Kior05ptvqrKyUvHx8erdu7eysrLUsmXL5uwRAIDzXqMCubKyUj/96U+1c+dOtW/fXomJiSopKdHzzz+vJ554QmvWrFFsbGxz9woAwHmrUR97euSRR1RaWqrVq1frlVde0bp16/TKK69o9erVKi8v16JFi5q7TwAAzmuNCuSXX35ZkyZNUu/evYPqvXv31sSJE/Xiiy82S3MAAFwoGhXIR48e1Te+8Y06t33jG9/Q4cOHm9ITAAAXnEYF8pVXXqlNmzbVue3ll1/WFVdc0aSmAAC40DTqTV1jxozR5MmTVVNTo5tvvlmXXHKJPvvsMz333HN6+umnlZeX18xtAgBwfmtUIN90003at2+f8vPz9fTTTwfqLVq00Pjx4zVs2LBmaxAAgAtBowL52LFjGjdunLKzs/X222/ryJEjOnjwoIYNG6aLLrqouXsEAOC816DXkHfs2KEf//jHWrlypSQpLi5O/fv3V//+/bVw4ULdcccd/KUnAAAaIexA/s9//qORI0fqyJEj6ty5c9C2qKgozZgxQ0ePHtUdd9yh0tLSZm8UAIDzWdiBvGzZMsXHx+tPf/qTvvvd7wZti46OVnZ2tgoLCxUTE6P8/PywGzh8+LDuu+8+9e/fX9dcc41uv/12bd26NbB9x44dys7OVs+ePTVw4EAVFBSEfd0AAESKsAO5uLhYP/vZz3TxxRefdp+EhASNGjVKxcXFYTcwefJkvfPOO5o/f76eeeYZde/eXWPGjNHevXtVUVGhUaNGqWPHjiosLNSECRO0aNEiFRYWhn39AABEgrDf1HXo0KGwPl+cmpoa9pL1/v379frrr+vJJ5/UNddcI0maOXOmNm/erOeff16tWrVSVFSU8vLy5PF4lJKSov3792v58uUaOnRouK0DAGC8sI+Q27Ztq7KysjPu9/nnn9d7FP1V8fHxWrZsma6++upAzbIs2batI0eOaOvWrcrIyJDH8+XvDX379lVJSYnKy8vDbR0AAOOFfYSckZGhoqIi/eAHP6h3v/Xr16tbt25hXWdcXJwGDBgQVHvhhRf00UcfqV+/flqwYIFSU1ODticlJUmSDhw4oISEhHDbD+HxhP8Gc7fbFfTvV1m1flmWFVqvo9bQumVZDeozXPXNE2mYxUzMYiZmMVvYgTx8+HDdfvvtmjNnjn7xi1+E/M3jmpoaLViwQK+99pqWLVvWqGa2bdumGTNm6MYbb1RmZqYefvhhRUVFBe1z6narq6sbdRuS5HJZio9v3eDLxcVFh9SO1lbJ43EH1SxLIbXG1D0ed6P6DFdd80QqZjETs5iJWcwUdiCnpaVp+vTpeuihh/Tss8/quuuu02WXXSafz6cDBw7ozTffVEVFhf7nf/5H119/fYMbeemllzR16lSlp6dr/vz5kqRWrVqppqYmaL9TQRwTE9Pg2zjF77dVWXks7P3dbpfi4qJVWXlcPp8/aJvX65PX6wuq2bZCao2pe70+VVQcDbvPcNU3T6RhFjMxi5mYxRnhHlg16Exdd955p7p27aqCggK9/PLLgXBs3bq1+vXrp9GjRys9Pb3Bza5evVoPPvigBg0apHnz5gWOipOTk0Netz71fbt27Rp8O1/l9Tb8AfT5/CGXs21btm2H7FtXraF127Yb1We46ponUjGLmZjFTMxipgafOvNb3/qWvvWtb0mSKioq5HK5mnS6zDVr1mj27NkaPny4ZsyYIZfry9cDMjIytHbtWvl8PrndJ5d0i4uL1alTpya9fgwAgGma9Gp4fHx8k8K4pKREDz30kAYNGqSxY8eqvLxchw4d0qFDh/TFF19o6NChqqqq0syZM7Vnzx4VFRVp1apVGjt2bFPaBgDAOI364xLN5W9/+5tqa2u1ceNGbdy4MWhbVlaW5syZoxUrVujBBx9UVlaWEhMTlZubq6ysLIc6BgDg7HA0kHNycpSTk1PvPj169NC6devOUUcAADjj/PkAFwAAEYxABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAI/TDeD0olq4VVXjC6nHtPTIZdsOdAQAOFsIZIOdqPEpv/CdkPq4n6SrTZTbgY4AAGcLS9YAABiAQAYAwABGBfLSpUs1fPjwoNr06dPVpUuXoK/+/fs71CEAAGeHMa8hr1y5UosXL1ZGRkZQfdeuXcrJyVF2dnag5nbz+ikA4PzieCB/+umnmjlzprZt26ZOnToFbfP5fNqzZ4/GjRunxMREhzoEAODsc3zJ+v3339dFF12kDRs2KD09PWjbvn37VF1drZSUFIe6AwDg3HD8CDkzM1OZmZl1btu9e7csy9KqVau0efNmuVwuDRgwQJMmTVJsbGyTbtfjCf93EbfbFfTvV1m1flmWFVqvo9ZcdcuyGtT/19U3T6RhFjMxi5mYxWyOB3J9PvjgA7lcLnXo0EH5+fnav3+/5s6dq927d2vVqlVyuRr3QLhcluLjWzf4cnFx0SG1o7VV8niCX9O2LIXUmrPu8bgb1f/X1TVPpGIWMzGLmZjFTEYH8oQJEzRy5EjFxcVJklJTU5WYmKhhw4bp3XffDVniDpffb6uy8ljY+7vdLsXFRauy8rh8Pn/QNq/XJ683+Gxatq2QWnPWvV6fKiqOht3/19U3T6RhFjMxi5mYxRnhHkAZHciWZQXC+JTU1FRJUmlpaaMDWZK83oY/gD6fP+Rytm3LruM0lnXVmqtu23aj+v+6uuaJVMxiJmYxE7OYyejF9ylTpmjMmDFBtXfffVeS1LlzZydaAgDgrDA6kIcMGaLXX39djz32mD766CO9+uqrmjFjhoYMGcI7rwEA5xWjl6xvuOEGLVq0SPn5+crPz1dsbKxuvvlmTZo0yenWAABoVkYF8pw5c0JqgwcP1uDBgx3oBgCAc8foJWsAAC4UBDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAN4nG4ADRfVwq2qGl9IPaalRy7bdqAjAEBTEcgR6ESNT/mF74TUx/0kXW2i3A50BABoKpasAQAwAIEMAIABjArkpUuXavjw4UG1HTt2KDs7Wz179tTAgQNVUFDgUHcAAJw9xgTyypUrtXjx4qBaRUWFRo0apY4dO6qwsFATJkzQokWLVFhY6FCXAACcHY6/qevTTz/VzJkztW3bNnXq1Clo21NPPaWoqCjl5eXJ4/EoJSVF+/fv1/LlyzV06FCHOgYAoPk5foT8/vvv66KLLtKGDRuUnp4etG3r1q3KyMiQx/Pl7w19+/ZVSUmJysvLz3WrAACcNY4fIWdmZiozM7PObaWlpUpNTQ2qJSUlSZIOHDighISEs94fAADnguOBXJ8TJ04oKioqqNayZUtJUnV1dZOu2+MJf3HA7XYF/ftVVq1flmWF1uuone26ZVlhzVXfPJGGWczELGZiFrMZHcitWrVSTU1NUO1UEMfExDT6el0uS/HxrRt8ubi46JDa0doqeTzBJ+OwLIXUzkXd43E3aK665olUzGImZjETs5jJ6EBOTk5WWVlZUO3U9+3atWv09fr9tiorj4W9v9vtUlxctCorj8vn8wdt83p98nqDT2Np2wqpnYu61+tTRcXRJs0TaZjFTMxiJmZxRrgHSkYHckZGhtauXSufzye3++QRYXFxsTp16tTk14+93oY/gD6fP+Rytm3LruP80XXVznbdtu0GzVXXPJGKWczELGZiFjMZvfg+dOhQVVVVaebMmdqzZ4+Kioq0atUqjR071unWAABoVkYHckJCglasWKGSkhJlZWVpyZIlys3NVVZWltOtAQDQrIxasp4zZ05IrUePHlq3bp0D3QAAcO4YfYQMAMCFgkAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAgQwAgAEIZAAADEAgAwBgAAIZAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAzgcboBNJ+oFm5V1fhC6tGtPDp+whv43qr162htlaLclqxz2SAA4LQI5PPIiRqf8gvfCannDE0PqluWJY/HrZ//+Gq1bsEiCQCYgGdjAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAGIJABADAAn0NGCL9l6Vi1N6Qe09Ijl2070BEAnP8IZIQ4Vu3V0mdCTzAy7ifpahPldqAjADj/sWQNAIABCGQAAAwQEUvWn3zyiTIzM0Pqv/71r3Xrrbc60BEAAM0rIgJ5165datmypV566SVZ1pd/nyg2NtbBrgAAaD4REci7d+9Wp06dlJSU5HQrAACcFRHxGvKuXbvUuXNnp9sAAOCsiYhA3r17t8rLy3XHHXfo29/+tm6//Xa99tprTrcFAECzMX7JuqamRvv27VN0dLRyc3MVExOjDRs26K677tLjjz+u6667rlHX6/GE/7uI2+0K+verrFp/0OvagXodNWPq1qla3fdDfTM15H47F+p7bCINs5iJWcx0Ps1yivGBHBUVpS1btsjj8SgqKkqSdPXVV2vv3r0qKChoVCC7XJbi41s3+HJxcdEhtaO1VfJ4gk+WcTLoQk+gYVrd7XbXeT/UNZN08joac7+dC3U9NpGKWczELGY6n2YxPpAlKSYmJqSWmpqqf/zjH426Pr/fVmXlsbD3d7tdiouLVmXlcfl8/qBtXq9PXq8vqGbbCqkZVbckj9stn8+nioqjIfvXNdOpel37O6m+xybSMIuZmMVMkTRLuAcyxgfyzp07dfvtt2v58uXq3bt3oP7ee+816Y1eXm/DH0Cfzx9yOdu2Zddxfue6aqbUrf9fsz4Z1KH3Q30zNeZ+OxfqemwiFbOYiVnMdD7NYvzie2pqqr75zW/qgQce0NatW7V37149/PDDevvtt5WTk+N0ewAANAvjj5BdLpfy8/M1b948TZo0SZWVlbrqqqv0+OOPq0uXLk63BwBAszA+kCWpbdu2euihh5xuAwCAs8b4JWsAAC4EBDIAAAYgkAEAMEBEvIaMs6OFx6WqmtDPGwMAzj0C+QJ2osan/MJ3Quo5Q9Md6AYALmwsWQMAYAACGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMwIlBcNb4LUvHqr0h9ZiWHrls24GOAMBcBDLOmmPVXi19JvRMYON+kq42UW4HOgIAc7FkDQCAAQhkAAAMQCADAGAAAhkAAAMQyAAAGIBABgDAAAQyAAAG4HPIaLLTnQCkua6HE4kAuBAQyGiy050AJGdoerNcDycSAXAhYMkaAAADEMgAABiAQAYAwAAEMgAABiCQAQAwAIEMAIABCGQAAAxAIAMAYABODIKwRbVwq6rGZ8ztxrRs2I/v6c4EFt3Ko+MnzDlDWK1fOlrHvE70ydnTcL4z6WecQEbYTtT4lF/Y9DNyNdftjvtJuqJiWoR9PfWdUex01+/EGcJM6pOzp+F8Z9LPOEvWAAAYICIC2e/3a/Hixbr++uuVnp6u0aNHa//+/U63BQBAs4mIQF66dKnWrl2rX//611q3bp0sy9Jdd92lmpoap1sDAKBZGB/INTU1+sMf/qAJEyZowIAB6tq1qxYsWKBPP/1UGzdudLo9AACahfGBvHPnTh09elR9+/YN1OLi4nTVVVdpy5YtDnYGAEDzMT6QS0tLJUmXXnppUD0pKUkHDx50oiUAAJqdZdtmf5jw2WefVW5urnbs2CGX68vfH3Jzc1VWVqaVK1c2+Dpt25bfH/7YliW5XC75/X59/d7y21Ll0eqgWlzrKFUeDX1926S6JUuxrVs41E9LuayQcp335Zmux+06/WPTHNdfV59ny6mfs1qv35g+T3+f1X+b9f0/E2mYxUzNNUtjf8Ybwu0O79jX+M8ht2rVStLJ15JP/bckVVdXKzo6ulHXaVmW3O6G39Nf/YXgFLekhItC+6irRr1+p7svw7meuh6b5rz+c6mFx2VMn/XdZ+EI53GJFMxipqbO0tSf8eZk/KNyaqm6rKwsqF5WVqbk5GQnWgIAoNkZH8hdu3ZVmzZt9OabbwZqlZWV2r59u3r37u1gZwAANB/jl6yjoqKUnZ2tefPmqW3bturQoYN++9vfKjk5WYMGDXK6PQAAmoXxgSxJEydOlNfr1axZs3TixAllZGSooKBAUVFRTrcGAECzMP5d1gAAXAiMfw0ZAIALAYEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAABPIZ+P1+LV68WNdff73S09M1evRo7d+/3+m2zujw4cO677771L9/f11zzTW6/fbbtXXr1sD2HTt2KDs7Wz179tTAgQNVUFDgYLfhKykpUa9evVRUVBSoReIs69ev10033aS0tDT94Ac/0AsvvBDYFknz1NbWasGCBRo4cKB69eqlO+64Q//6178C2yNllqVLl2r48OFBtTP1bupzQ12zvPLKKxo6dKh69eqlzMxMzZ07VydOnAhsj6RZvmrWrFnKzMwMqpk6S1hs1OvRRx+1r7vuOvvvf/+7vWPHDnv06NH2oEGD7Orqaqdbq9eoUaPsH/7wh/aWLVvsvXv32rNnz7Z79Ohh79mzx/7888/ta6+91p45c6a9Z88e+5lnnrHT0tLsZ555xum261VTU2Pfcsstdmpqql1YWGjbth2Rs6xfv97u1q2bvXLlSnvfvn32kiVL7K5du9r/+te/Im6eRYsW2d/5znfs1157zd63b589c+ZM+5prrrFLS0sjZpbHH3/c7tKli52dnR2ohdO7ic8Ndc2yZcsWu1u3bvbvf/97e9++ffarr75qDxgwwL7nnnsC+0TKLF+1ceNGOzU11b7hhhuC6ibOEi4CuR7V1dV2r1697DVr1gRqR44csXv06GE///zzDnZWv3379tmpqan2tm3bAjW/328PGjTIXrhwoZ2fn29ff/31dm1tbWD7I488Yg8ePNiJdsP2yCOP2MOHDw8K5Eibxe/32zfccIM9Z86coPro0aPt/Pz8iJvnhz/8of3www8Hvv/iiy/s1NRU+69//avxs5SWltpjxoyxe/bsaX/ve98LeuI/U++mPTfUN8uUKVPsUaNGBe2/fv16+6qrrrKrq6sjapZTPv30U7tv3752dnZ2UCCbNktDsWRdj507d+ro0aPq27dvoBYXF6errrpKW7ZscbCz+sXHx2vZsmW6+uqrAzXLsmTbto4cOaKtW7cqIyNDHs+XpzLv27evSkpKVF5e7kTLZ7RlyxatW7dOc+fODapH2iwffvihPvnkE918881B9YKCAo0dOzbi5rn44ou1adMmffzxx/L5fFq3bp2ioqLUrVs342d5//33ddFFF2nDhg1KT08P2nam3k17bqhvltGjRys3NzfkMl6vV1VVVRE1iyTZtq177rlHP/rRj9SnT5+gbabN0lAEcj1KS0slffk3mU9JSkrSwYMHnWgpLHFxcRowYEDQH9944YUX9NFHH6lfv34qLS0N+VvSSUlJkqQDBw6c017DUVlZqdzcXM2aNSvksYi0Wfbt2ydJOnbsmMaMGaPrrrtOt956q1555RVJkTfPzJkz5fF4dOONNyotLU0LFizQwoULdfnllxs/S2Zmph555BF94xvfCNl2pt5Ne26ob5arrrpKXbt2DXxfU1Ojxx9/XN27d1fbtm0jahZJWrlypQ4dOqTJkyeHbDNtloYikOtx/PhxSQr5q1ItW7ZUdXW1Ey01yrZt2zRjxgzdeOONyszM1IkTJ+qcSZKRc+Xl5alnz54hR5WSIm6WqqoqSdK0adM0ZMgQ/eEPf9B3vvMdjRs3TsXFxRE3z969exUXF6ff/e53WrdunW655RZNmzZNO3fujLhZvupMvUfqc4PX61Vubq727Nmj+++/X1JkPc/t3LlTS5Ys0W9/+9s6/9pfJM1Sl4j484tOadWqlaSTv1Ge+m/p5P+Q0dHRTrXVIC+99JKmTp2q9PR0zZ8/X9LJuWpqaoL2O/XDGhMTc857rM/69eu1detWPffcc3Vuj6RZJKlFixaSpDFjxigrK0uS1K1bN23fvl2PP/54RM3zySef6Je//KVWrlyp3r17S5LS0tK0Z88ePfrooxE1y9edqfdIfG6oqqrSpEmT9Oabb2rx4sWB5eBImaW6ulpTp07V3XffHXTE/1WRMsvpcIRcj1PLHmVlZUH1srKykOUsE61evVoTJkxQ//79tXz58sAPaHJycp0zSVK7du3OeZ/1KSwsVHl5eeBjNb169ZIk3X///frBD34QUbNICvzcpKamBtU7d+6sjz/+OKLm+fe//63a2lqlpaUF1dPT07Vv376ImuXrztR7pD03lJWV6c4779Rbb72l5cuXB31UKFJmeeedd/TBBx9oyZIlgeeC3//+9zpw4IB69eqlDRs2RMwsp0Mg16Nr165q06aN3nzzzUCtsrJS27dvDxwRmGrNmjWaPXu27rzzTi1cuDBoCScjI0Pbtm2Tz+cL1IqLi9WpUyclJCQ40e5pzZs3T3/5y1+0fv36wJckTZw4UcuWLYuoWaSTr+e1bt1a77zzTlB99+7duvzyyyNqnlNPfrt27Qqq7969W1dccUVEzfJ1Z+o9kp4bjhw5ohEjRujzzz/XmjVrgt7wJEXO81yPHj304osv6tlnnw08F9x2221KSkrS+vXrlZmZGTGznJbTb/M23fz58+0+ffrYL730UuAzbd/97neN/kzbhx9+aHfv3t0eP368XVZWFvRVWVlpf/bZZ3ZGRoY9bdo0+4MPPrALCwvttLQ0u6ioyOnWw/LVjz1F4iy/+93v7F69etnPPfecvX//fnvp0qV2165d7TfeeCOi5vH5fPYdd9xhf+9737OLi4vtkpISe8GCBXa3bt3st956K6JmmTZtWtDHa8Lp3dTnhq/PMm3aNLt79+52cXFxyPOB1+u1bTtyZvm6xYsXh3wO2dRZwsFryGcwceJEeb1ezZo1SydOnFBGRoYKCgrqfEOBKf72t7+ptrZWGzdu1MaNG4O2ZWVlac6cOVqxYoUefPBBZWVlKTExUbm5uYHXNCNJQkJCxM0ybtw4RUdHa8GCBfr000+VkpKiRx99VNdee60kRcw8LpdLS5cu1cKFCzV9+nQdOXJEqampWrlypXr27Ckpcmb5unB+riLhucHv9+svf/mLamtrNWLEiJDtL7/8si677LKImCVckTyLZdu27XQTAABc6HgNGQAAAxDIAAAYgEAGAMAABDIAAAYgkAEAMACBDACAAQhkAAAMQCADOKc49QFQNwIZOI+9+eab6tKlS+DcvkVFRerSpYs+/vhjR/rZtm2bxo4dG/j+448/VpcuXVRUVORIP4BJOHUmcAEZOHCg1q1bp6SkJEdu/+mnn9aePXsC3yclJWndunW6/PLLHekHMAmBDFxA2rZtq7Zt2zrdRkBUVFTgvNfAhY4la+AcyszM1EMPPaQRI0bommuu0X333afDhw/rvvvu07e//W2lpaXpv/7rv1RcXBx0uc8//1wPPPCAbrjhBl199dXq06ePxo8fH7L0vHbtWg0ePFg9evRQdna2Dhw4ELT960vW99xzj0aOHKnCwkINHjxYV199tX74wx/q1VdfDbrcW2+9pTvvvFM9e/bUwIEDtWrVKo0cOVL33HNP2LPfc889+tOf/qRPPvkksEz99SXroqIipaWladu2bRo6dKjS0tI0ePBgvfLKK/rwww81YsQIpaena9CgQfrzn/8cdP0HDhzQ5MmT1adPH6Wnp2vEiBHavn172P0BTiOQgXPsiSeeUJcuXfToo4/qRz/6kUaMGKGXX35Zv/jFL7RkyRIlJyfrZz/7WSCUbdvW2LFj9frrr2vKlCkqKCjQuHHj9M9//lP33Xdf4HpXr16t+++/X9dff72WLl2q9PR03XvvvWfs57333lNBQYEmTpyo3/3ud/J4PJo4caKOHDkiSdq7d69GjhwpSZo/f74mTJigZcuWadu2bQ2ae9y4cRowYIASExO1bt06DRw4sM79vF6vJk+erNtuu01Lly5Vy5YtNXXqVOXk5GjgwIFatGiREhMTNW3aNJWWlko6+QvLbbfdpvfff1/33nuvHnnkEfn9ft15553au3dvg/oEnMKSNXCOJSUl6Z577pHL5dJTTz2lnTt36qmnnlJ6erokqX///ho+fLjmzZunwsJClZWVKTo6WtOmTQv8kfVrr71WH3/8sdauXSvpZGgvXbpUgwcP1qxZsyRJ/fr1U1VVVWCf0/niiy9UVFQUeB03JiZG2dnZeuONNzR48GD9/ve/V5s2bbRixQpFR0dLkq688krddtttDZr78ssvV9u2bYOWqY8dOxayn9/vV05Ojm699VZJJ//A/OTJkzVixAiNGjVKknTJJZdo6NCheu+995ScnKxVq1bp8OHDevLJJ9WhQ4fA/XjTTTdp0aJFWrx4cYN6BZzAETJwjqWkpMjlOvm/XnFxsRITE9W9e3d5vV55vV75fD7dcMMNeu+993TkyBG1a9dOf/zjH9W7d28dOHBAxcXFWr16tf71r3+ptrZWkvThhx+qvLxcN954Y9Btff/73z9jP23btg16U1VycrIk6fjx45KkN954QwMGDAiEsST16tUrEHxnQ69evQL/fckll0hS0GvNF198saSTYS2dvB+7deumdu3aBe5Hl8ul/v3765///OdZ6xNoThwhA+fYqYCRpMOHD+vQoUPq3r17nfseOnRIF110kTZs2KD58+fr4MGDuvjii9W1a1e1atUqsN+p5eWvv2ErMTHxjP18NWglybIsSSePVKWTy8EJCQkhlwvnuhurTZs2IbWvzvt1hw8f1v79+097Px4/fjxkTsA0BDLgoNjYWHXs2FHz5s2rc/tll12mrVu3atq0acrOztaYMWMCR7C/+c1vAq/jxsfHS5LKy8uDLn/48OEm95icnBxyvaduq1OnTk2+/uYQGxurPn36KDc3t87tUVFR57gjoOFYsgYc1KdPHx08eFAJCQlKS0sLfBUXF2vFihVyu91666235Pf7NXHixEAY+3y+wFKs3+9Xx44ddemll+qvf/1r0PVv2rSpyT1mZGRo8+bNqq6uDtR27NjRqJOLnFqqb259+vRRSUmJOnXqFHQ/btiwQU8//bTcbvdZuV2gORHIgINuueUWtW/fXqNGjdKf/vQnvfHGG5o/f74WLFigpKQktWjRQj169JAk/epXv9Ibb7yhF198UaNGjdLOnTslnXxjlGVZmjp1qjZt2qRZs2bpH//4h5YsWaInn3yyyT3m5OToiy++0M9+9jNt2rRJzz77rMaPHy/LsgLL2+GKi4vTZ599pldffVVlZWVN7u2UkSNHyu/3a+TIkfrLX/6i4uJi3XvvvfrjH/+oK6+8stluBzibCGTAQTExMXriiSf0rW99S7/97W9111136cUXX9SUKVM0ffp0SSffUX3ffffprbfe0l133aWHH35Y7du315IlSyQpsGw9ZMgQLViwQG+//bbuvvtubdq0Sb/61a+a3OMVV1yhgoICVVdXa+LEiVqwYIHuuusuJSYmqnXr1g26rltuuUUdOnTQ+PHjtX79+ib3dkq7du20du1adejQQXl5ecrJydG///1vPfjgg4GPbAGms2zO9A6gHsXFxWrRokXgI1fSyTeRfec731Fubq5++tOfOtgdcP7gTV0A6vX+++9r8eLFmjx5srp3766Kigr94Q9/UGxsrIYMGSK/3x94R3Z93G53g5e4gQsJgQygXqNHj1ZNTY2efPJJHTx4UDExMerTp4/mzp2rtm3b6tFHHw0sn9fnj3/8o6699tpz0DEQmViyBtAkn376aVhv0OrUqVOdny8GcBKBDACAAXiXNQAABiCQAQAwAIEMAIABCGQAAAxAIAMAYAACGQAAAxDIAAAYgEAGAMAA/wcSgJ5yWxTL2gAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(articles['reading_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation Coefficient: 0.96\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAk8AAAG1CAYAAADgJhCMAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHT0lEQVR4nO3deXxU1f3/8fedmUwmAQMJBAIoi0ACCAmhRKnIYpRqraLAr/r1W1ABEQXh68KmWMS6VwqCGKosbtiKGIrUr9qCrWL7RQqURWQNS1wQAiEQIevM3N8faUaGhCR3Mkkmyev5ePAgOefOnZOPF3lz7plzDdM0TQEAAKBKbHU9AAAAgPqE8AQAAGAB4QkAAMACwhMAAIAFhCcAAAALCE8AAAAWEJ4AAAAsIDwBAABYQHgCAACwwFHXAwhVpmnK6w3u5us2mxH0czYG1M06ahYY6mYdNQsMdbOuKjWz2QwZhlHjYyE8XYDXa+rkybNBO5/DYVN0dBPl5ubJ7fYG7bwNHXWzjpoFhrpZR80CQ92sq2rNYmKayG6v+fDEbTsAAAALCE8AAAAWEJ4AAAAsIDwBAABYQHgCAACwgPAEAABgAeEJAADAAsITAACABYQnAAAACwhPAAAAFhCeAABArTANQ3lur06cKVKe2yuzFp5DVxN4th0AAKhxHsNQWvoObd133NeWnBCrCcMTZTfr10OSmXkCAAA1yiwnOEnS1r3HlbZqR72bgSI8AQCAGpVf7CkTnEpt3Xtc+cWeWh5R9RCeAABAjcorcFerP9QQngAAQI2KdFW8xLqy/lBDeAIAADUqIsyu5ITYcvuSE2IVEWav5RFVD+EJAADUKMM0NWF4YpkAVfppO6Oefdqufs2TAQCAeslumrp/eKLyiz3KK3Ar0uVQRJi93gUnifAEAABqiWGainTYFNnUWdJQD4OTxG07AAAASwhPAAAAFhCeAAAALCA8AQAAWEB4AgAAsIDwBAAAYAHhCQAAwALCEwAAgAWEJwAAAAsITwAAABaEXHhKS0vTqFGjLtj/2GOPKTU11a/N6/VqwYIFGjBggJKSkjRmzBhlZmbW9FABAEAjFFLh6fXXX9eCBQsu2L9u3TqtXLmyTHtaWpreeecdPfXUU1qxYoUMw9C4ceNUVFRUk8MFAACNUEiEp2PHjunuu+/W/Pnz1alTp3KPycrK0q9//Wtdfvnlfu1FRUVatmyZJk2apEGDBqlbt26aN2+ejh07prVr19bG8AEAQCMSEuHpq6++UrNmzbRmzRolJSWV6TdNUzNmzNDNN99cJjzt2bNHZ8+eVb9+/XxtUVFR6tGjhzZt2lTjYwcAAI2Lo64HIEmpqall1jGd6/XXX9fx48f1+9//Xq+88opf39GjRyVJbdq08Wtv1aqVvv/++2qNy+EIXra0221+v6NqqJt11Cww1M06ahYY6mZdqNUsJMJTRfbs2aOFCxfq7bffltPpLNOfn58vSWX6wsPDdfr06YDf12YzFB3dJODXX0hUVETQz9kYUDfrqFlgqJt11Cww1M26UKlZSIenwsJCTZkyRffdd5+6detW7jEul0tSydqn0q9LXxsREXiRvV5Tubl5Ab/+fHa7TVFREcrNzZfH4w3aeRs66mYdNQsMdbOOmgWGullX1ZpFRUXUyuxUSIen7du3a//+/Vq4cKFefvllSVJxcbHcbreSk5P1xBNPqGPHjpJKFpS3b9/e99qsrKwLBq6qcruDf1F7PN4aOW9DR92so2aBoW7WUbPAUDfrQqVmIR2eEhMT9de//tWv7a233tJf//pXvfXWW2rRooWcTqeaNm2qjRs3+sJTbm6udu3apZEjR9bFsAEAQAMW0uHJ5XKpQ4cOfm3NmjWTw+Hwax85cqTmzJmjmJgYtWvXTi+88ILi4uI0ZMiQ2h4yAABo4EI6PFXV5MmT5Xa79dhjj6mgoEApKSlaunRpuQvMAQAAqsMwTdOs60GEIo/Hq5MnzwbtfA6HTdHRTZSTczYk7tfWF9TNOmoWGOpmHTULDHWzrqo1i4lpUisLxkNjwwQAAIB6gvAEAABgAeEJAADAAsITAACABYQnAAAACwhPAAAAFhCeAAAALCA8AQAAWEB4AgAAsIDwBAAAYAHhCQAAwALCEwAAgAWEJwAAAAsITwAAABYQngAAACwgPAEAAFhAeAIAALCA8AQAAGAB4QkAAMACwhMAAIAFhCcAAAALCE8AAAAWEJ4AAAAsIDwBAABYQHgCAACwgPAEAABgAeEJAADAAsITAACABYQnAAAACwhPAAAAFhCeAAAALCA8AQAAWEB4AgAAsIDwBAAAYEHIhae0tDSNGjXKr+1vf/ubRowYoeTkZKWmpur5559XQUGBr9/r9WrBggUaMGCAkpKSNGbMGGVmZtb20AEAQCMQUuHp9ddf14IFC/zaNm/erPvvv1/XXXedVq9erdmzZ+ujjz7SE0884TsmLS1N77zzjp566imtWLFChmFo3LhxKioqqu0fAQAANHAhEZ6OHTumu+++W/Pnz1enTp38+t555x3169dP99xzjzp06KCBAwfqwQcf1Jo1a1RUVKSioiItW7ZMkyZN0qBBg9StWzfNmzdPx44d09q1a+voJwIAAA1VSISnr776Ss2aNdOaNWuUlJTk1zdmzBhNmzatzGvcbrfOnDmjPXv26OzZs+rXr5+vLyoqSj169NCmTZtqfOwAAKBxcdT1ACQpNTVVqamp5fb16NHD7/uioiK99tpruuyyyxQTE6PNmzdLktq0aeN3XKtWrfT9999Xa1wOR/Cypd1u8/sdVUPdrKNmgaFu1lGzwFA360KtZiERnqrK7XZr2rRpysjI0Ntvvy1Jys/PlyQ5nU6/Y8PDw3X69OmA38tmMxQd3STwwV5AVFRE0M/ZGFA366hZYKibddQsMNTNulCpWb0JT2fOnNEDDzygjRs3asGCBb7bey6XS1LJjFTp15JUWFioiIjAi+z1msrNzaveoM9ht9sUFRWh3Nx8eTzeoJ23oaNu1lGzwFA366hZYKibdVWtWVRURK3MTtWL8JSVlaVx48bp22+/1eLFi/3WN5XersvKylL79u39XtOtW7dqva/bHfyL2uPx1sh5GzrqZh01Cwx1s46aBYa6WRcqNQuNm4cVOH36tO68806dPHlSf/jDH/yCkyR169ZNTZs21caNG31tubm52rVrl/r27VvbwwUAAA1cyM88Pfvss/rmm2+0ZMkSxcTE6Pjx476+mJgYOZ1OjRw5UnPmzFFMTIzatWunF154QXFxcRoyZEgdjhwAADREIR2evF6vPvzwQxUXF+vOO+8s0//JJ5/o4osv1uTJk+V2u/XYY4+poKBAKSkpWrp0aZlF5AAAANVlmKZp1vUgQpHH49XJk2eDdj6Hw6bo6CbKyTkbEvdr6wvqZh01Cwx1s46aBYa6WVfVmsXENKmVBeMhv+YJAAAglBCeAAAALCA8AQAAWEB4AgAAsIDwBAAAYAHhCQAAwALCEwAAgAWEJwAAAAsITwAAABYQngAAACwgPAEAAFhAeAIAALCA8AQAAGAB4QkAAMACwhMAAIAFhCcAAAALCE8AAAAWEJ4AAAAsIDwBAABYQHgCAACwgPAEAABgAeEJAADAAsITAACABYQnAAAACwhPAAAAFhCeAAAALCA8AQAAWEB4AgAAsIDwBAAAYAHhCQAAwALCEwAAgAWEJwAAAAsITwAAABaEXHhKS0vTqFGj/Np2796tkSNHqnfv3ho8eLCWLl3q1+/1erVgwQINGDBASUlJGjNmjDIzM2tz2AAAoJEIqfD0+uuva8GCBX5tOTk5Gj16tDp27Kj09HRNmjRJ8+fPV3p6uu+YtLQ0vfPOO3rqqae0YsUKGYahcePGqaioqLZ/BAAA0MA56noAknTs2DHNnDlTW7ZsUadOnfz63n33XTmdTs2ePVsOh0OdO3dWZmamFi9erBEjRqioqEjLli3T1KlTNWjQIEnSvHnzNGDAAK1du1a/+MUv6uJHAgAADVRIzDx99dVXatasmdasWaOkpCS/vs2bNyslJUUOx485r1+/fjp06JCys7O1Z88enT17Vv369fP1R0VFqUePHtq0aVOt/QwAAKBxCImZp9TUVKWmppbbd/ToUcXHx/u1tWrVSpJ05MgRHT16VJLUpk2bMsd8//331RqXwxG8bGm32/x+R9VQN+uoWWCom3XULDDUzbpQq1lIhKeKFBQUyOl0+rWFh4dLkgoLC5Wfny9J5R5z+vTpgN/XZjMUHd0k4NdfSFRURNDP2RhQN+uoWWCom3XULDDUzbpQqVnIhyeXy1Vm4XdhYaEkKTIyUi6XS5JUVFTk+7r0mIiIwIvs9ZrKzc0L+PXns9ttioqKUG5uvjweb9DO29BRN+uoWWCom3XULDDUzbqq1iwqKqJWZqdCPjzFxcUpKyvLr630+9atW8vtdvva2rdv73dMt27dqvXebnfwL2qPx1sj523oqJt11Cww1M06ahYY6mZdqNQsNG4eViAlJUVbtmyRx+PxtW3YsEGdOnVSixYt1K1bNzVt2lQbN2709efm5mrXrl3q27dvXQwZAAA0YCEfnkaMGKEzZ85o5syZysjI0KpVq/TGG29o/PjxkkrWOo0cOVJz5szRJ598oj179ujBBx9UXFychgwZUsejBwAADU3I37Zr0aKFlixZoqefflrDhg1TbGyspk2bpmHDhvmOmTx5stxutx577DEVFBQoJSVFS5cuLbOIHAAAoLoM0zTNuh5EKPJ4vDp58mzQzudw2BQd3UQ5OWdD4n5tfUHdrKNmgaFu1lGzwFA366pas5iYJrWyYDzkb9sBAACEEsITAACABYQnAAAACwhPAAAAFgQlPBUWFop15wAAoDEIODwdPHhQDzzwgC6//HIlJydr165dmj17tt56661gjg8AACCkBBSedu/erf/3//6fvvrqK910002+WaewsDA988wz+tOf/hTUQQIAAISKgDbJfP7559WzZ08tW7ZMkvT2229LkmbOnKmCggK9+eabfptYAgAANBQBzTxt27ZNd911lxwOhwzD8Ou74YYbdPjw4WCMDQAAIOQEFJ7Cw8NVUFBQbt+pU6d4LAoAAGiwAgpP/fv314IFC3T06FFfm2EYOnv2rJYtW6Yrr7wyaAMEAAAIJQGteZo6dapuu+02XX/99erWrZsMw9Bzzz2nQ4cOyTRNzZ07N9jjBAAACAkBzTy1adNG77//vu68806Zpqn27dsrLy9PN954o1atWqVLLrkk2OMEAAAICQHNPElSdHS0HnzwwWCOBQAAIOQFHJ6OHTumnTt36ocffii3/5Zbbgn01AAAACEroPD04YcfasaMGSoqKiq33zAMwhMAAGiQAgpPL774onr16qVHH31UzZs3D/KQAAAAQldA4SkrK0szZ87UZZddFuzxAAAAhLSAPm3Xu3dvHTp0KNhjAQAACHkBzTw9/vjjuvfee3XmzBklJiYqIiKizDEpKSnVHhwAAECoCSg8HT58WCdOnNDChQslye/5dqZpyjAM7d69OzgjBAAACCEBhafnn39eF198scaPH6+WLVsGe0wAAAAhK6DwdOTIES1atEj9+/cP9ngAAABCWkALxuPj4/0eCgwAANBYBDTz9Oijj+rhhx+Wx+NR79691bRp0zLHtG3bttqDAwAACDUBhae77rpLbrdbs2bN8lssfi4WjAMAgIYooPA0e/bsC4YmAACAhiyg8DR8+PBgjwMAAKBeqHJ4Wr16tQYNGqTo6GitXr260uN5MDAAAGiIqhyeZsyYoXfffVfR0dGaMWNGhccahkF4AgAADVKVw9Mnn3yi2NhY39cAAACNUZX3eWrXrp2cTqckadOmTYqMjFS7du3K/HI6nfrwww9rbMAAAAB1KaBNMh955BF988035fbt3r1bCxYsqNagAAAAQlWVb9uNHz9eGRkZkkoe/jtx4kTfTNS5srOz1b59++CNEAAAIIRYCk8rV66UJP3pT39Sjx49FBMT43eMzWZTVFRU0LcyKC4u1sKFC/X+++/r9OnT6t69u6ZMmaI+ffpIKpntevrpp7Vz5041b95co0aN0tixY4M6BgAAAMlCeOrTp48vrEjShAkTdMkll1T6uk2bNumyyy5TZGRkYCOUtGjRIqWnp+u5557TJZdcosWLF2vcuHH68MMP5XQ6NXr0aF177bV64okntG3bNj3xxBNq3ry5RowYEfB7AgAAlCegTTKfffbZKh3n8Xh0xx136L333tNll10WyFtJKvl034033qirrrpKUsm2CStXrtS2bdt0+PBhOZ1OzZ49Ww6HQ507d1ZmZqYWL15MeAIAAEEX0IJxK0zTrPY5mjdvrr///e/69ttv5fF4tGLFCjmdTnXv3l2bN29WSkqKHI4fc2C/fv106NAhZWdnV/u9AQAAzhXQzFNtmzlzph588EFdc801stvtstlsmj9/vtq3b6+jR48qPj7e7/hWrVpJko4cOaIWLVoE/L4OR/Cypd1u8/sdVUPdrKNmgaFu1lGzwFA360KtZvUiPB04cEBRUVF6+eWX1bp1a61cuVLTp0/X8uXLVVBQUOZTf+Hh4ZKkwsLCgN/TZjMUHd2kWuMuT1RURNDP2RhQN+uoWWCom3XULDDUzbpQqVnIh6fvvvtOU6dO1euvv66+fftKknr16qWMjAy99NJLcrlcKioq8ntNaWiqziJ1r9dUbm5e4AM/j91uU1RUhHJz8+XxeIN23oaOullHzQJD3ayjZoGhbtZVtWZRURG1MjsV8uFpx44dKi4uVq9evfzak5KStH79erVt21ZZWVl+faXft27dulrv7XYH/6L2eLw1ct6GjrpZR80CQ92so2aBoW7WhUrNQuPmYQXatGkjSdq7d69f+759+9ShQwelpKRoy5Yt8ng8vr4NGzaoU6dO1VrvBAAAUJ6QD0+JiYnq27evpk+fri+++EKHDx/Wiy++qA0bNuiee+7RiBEjdObMGc2cOVMZGRlatWqV3njjDY0fP76uhw4AABqgkL9tZ7PZlJaWphdffFGPPPKITp8+rfj4eL3++uvq3bu3JGnJkiV6+umnNWzYMMXGxmratGkaNmxY3Q4cAAA0SIYZjI2YLsA0Tb388su67bbbFBsbW1NvUyM8Hq9OnjwbtPM5HDZFRzdRTs7ZkLhfW19QN+uoWWCom3XULDDUzbqq1iwmpknoLhh/5JFHLthns9kUGRmpjh076oYbbtD9998f8OAAAABCTUDh6ejRo/r3v/+twsJCtWvXTrGxscrOzta3334rm82mli1bKjs7W4sWLdIf//jHKj0DD6gvTMNQfrFHeQVuRbocigizy6i5CVwAQIgJKDxdffXV2r9/v9544w3fuiNJ2r17tyZOnKjx48fr+uuv1/jx4zV37lzNmzcvWOMF6pTHMJSWvkNb9x33tSUnxGrC8ETZCVAA0CgEdGPw9ddf18MPP+wXnCSpe/fu+p//+R+98soratasmcaMGaONGzcGY5xAnTPLCU6StHXvcaWt2iHTMOpoZACA2hRQeMrJyVFMTEy5fc2aNfM9kDcmJkZ5ecHbpRuoS/nFnjLBqdTWvceVX+wptw8A0LAEFJ569OihJUuWlHksSlFRkZYtW6bu3btLkr766ivfJpdAfZdX4K5WPwCgYQhozdOUKVM0evRopaamavDgwWrRooWys7P12Wef6cyZM1qyZIk2b96suXPn6r777gv2mIE6Eemq+I9LZf0AgIYhoJmn5ORkrVq1SldeeaU+//xzLVu2TBs3btSAAQP0/vvv6yc/+YmKi4s1efJk3XvvvcEeM1AnIsLsSk4of7+y5IRYRYTZa3lEAIC6UKObZNZnbJIZGkKtbh7DUNqqHdq6N3Q/bRdqNasvqJt11Cww1M26BrFJpiT98MMP+uKLL5SXl6fy8tctt9xSnXEBIclumrp/eCL7PAFAIxZQePrss8/0wAMPKD8/v9x+wzAIT2iwDNNUpMOmyKbOkgaCEwA0KgGFp7lz5+rSSy/VI488otatW8tmq/kpMgAAgFAQUHg6ePCg0tLS1Ldv32CPBwAAIKQFNGXUtm1bnTlzJthjAQAACHkBhafx48fr5Zdf1rfffhvs8QAAAIS0gG7b/fnPf9axY8c0ZMgQxcTEyOVy+fUbhqF169YFZYAAAAChJKDwFBcXp7i4uGCPBQAAIOQFFJ6effbZYI8DAACgXqhyeDpy5IhiY2MVFhamI0eOVHp827ZtqzUwAACAUFTl8HTNNddoxYoVSkxMVGpqqgzDqPD43bt3V3twAAAAoabK4emZZ57RJZdc4vu6svAEAADQEFU5PA0bNsz39fDhw2tkMAAAAKGuyuFp06ZNlk6ckpJieTAAAAChrsrhadSoUb5bdaZp+t22M//zYNRz21jzBAAAGqIqh6c333zT9/WRI0f061//WiNGjNDPf/5zxcbG6tSpU/rb3/6md955R7/5zW9qZLAAAAB1rcrh6fLLL/d9PWrUKN111116+OGH/Y7p06ePXC6XXnvtNd1www3BGyUAAECICOjZdjt27NBPf/rTcvuSk5O1b9++ag0KQFmmYSjP7dWJM0XKc3tl8olXAKgTAT+e5dNPP9WVV15Zpu/jjz9W+/btqz0wAD/yGIbS0ndo677jvrbkhFhNGJ4o+3/WHAIAakdA4Wn06NGaPXu2jh8/rtTUVMXExOjEiRP6+OOP9emnn2ru3LnBHifQaJnlBCdJ2rr3uNJW7dD9wxNlEKAAoNYEFJ7+67/+S263W4sWLdJHH33ka2/Tpo3mzJmjn//850EbINDY5Rd7ygSnUlv3Hld+sUeRjoDuwAMAAhBQeJKkkSNHauTIkTpw4IByc3MVHR2tjh07BnFoACQpr8BdaX9kU2ctjQYAEHB4KtW5c2e/7/Py8rR582YNHDiwuqcGICnSVfEf08r6AQDBFdD/db/77jvNmjVLmzZtUnFxcbnHsEkmEBwRYXYlJ8Rq696yt+6SE2IVEWaXWPMEALUmoIUSzz77rLZu3apbb71V3bt3V58+fTRmzBglJCTIMAwtXLgw2OMEGhQr2w4YpqkJwxOVnBDr1176aTsWiwNA7Qpo5mnTpk164IEHdMcdd+jtt9/WunXrNHXqVD300EMaM2aMPvnkE11zzTVBHejq1av16quv6ptvvlH79u11//33+xam7969W08//bR27typ5s2ba9SoURo7dmxQ3x8IlkC2HbCbpu4fnqj8Yk/JGieXQxFhdoITANSBgGaezp49q+7du0sqWfNUeovObrfrV7/6lb744ovgjVDS+++/r0cffVS33XabPvjgA91www166KGHtHXrVuXk5Gj06NHq2LGj0tPTNWnSJM2fP1/p6elBHQMQDJVtO1DZDFSkw6aWTZ2KdNgITgBQRwKaeWrVqpWOHy/5n3+HDh10+vRpZWVlqVWrVmrWrJmys7ODNkDTNDV//nzdeeeduvPOOyVJEydO1L///W/961//0r/+9S85nU7Nnj1bDodDnTt3VmZmphYvXqwRI0YEbRxAMLDtAADUfwH9X3rQoEGaP3++/v3vf6tNmzaKi4vTsmXLdObMGaWnp6t169ZBG+DBgwf13Xff6aabbvJrX7p0qcaPH6/NmzcrJSVFDsePObBfv346dOhQUEMcEAxV2XYAABDaApp5mjx5snbu3KkFCxbo9ddf14MPPqgZM2bojTfekCTNmjUraAM8fPiwpJItEMaOHatdu3bp4osv1n333afU1FQdPXpU8fHxfq9p1aqVJOnIkSNq0aJFwO/tCOIMgN1u8/sdVdPQ6hbpCqu0v7rXXUOrWW2hbtZRs8BQN+tCrWYBhafo6GitXLlSWVlZkqShQ4eqbdu22rZtmxITE3X55ZcHbYBnzpyRJE2fPl3333+/pkyZor/85S+aMGGCXnvtNRUUFMjp9N8gMDw8XJJUWFgY8PvabIaio5sEPvALiIqKCPo5G4OGUjdHXlGF2w7ENHPposjgbHjZUGpW26ibddQsMNTNulCpWbV212vVqpV++OEHZWVlKTExUcnJybLb7cEamyQpLKzkX+pjx47VsGHDJEndu3fXrl279Nprr8nlcqmoqMjvNaWhKTIyMuD39XpN5ebmBfz689ntNkVFRSg3N18ejzdo523oGmLdJgxPVNqqHX4BKjkhVhNGJMpdWKycwvL3Tquqhliz2kDdrKNmgaFu1lW1ZlFREbUyOxVweNq4caPmzJmjnTt3yjAMrVy5UkuWLFHr1q01Y8aMoA0wLi5OksrcmuvSpYs+/fRTtWvXzjcDVqr0++quvXK7g39RezzeGjlvQ9eQ6maXyt92wGvK7Q3eJ+gaUs1qE3WzjpoFhrpZFyo1CyiebdiwQWPHjpXL5dKUKVNk/ucj0927d9ebb76p1157LWgD7NGjh5o0aaLt27f7te/bt0/t27dXSkqKtmzZIo/H4ze+Tp06VWu9E1CT2HYAAOqvgMLTiy++qGuuuUZvvfWW7rzzTl94uueee3T33Xdr5cqVQRugy+XS3XffrZdfflkffPCBvv76ay1atEj//Oc/NXr0aI0YMUJnzpzRzJkzlZGRoVWrVumNN97Q+PHjgzYGAACAUgHdttu9e7cmTpwoSTLO29Svf//+vk/dBcuECRMUERGhefPm6dixY+rcubNeeuklXXHFFZKkJUuW6Omnn9awYcMUGxuradOm+dZHAQAABFNA4emiiy7ybZJ5vu+//14XXXRRtQZVntGjR2v06NHl9iUmJmrFihVBf08AAIDzBXTb7pprrtG8efP05Zdf+toMw9DRo0f1+9//XoMHDw7W+AAAAEJKQDNPDz/8sLZv365bb71VLVu2lCQ99NBDOnr0qNq0aaOHHnooqIMEAAAIFQGFp3nz5unxxx9XRkaGvvjiC506dUoXXXSRRo0apeHDhysiIjQ2sQIAAAi2gMLTn//8Z1133XW69dZbdeuttwZ7TAAAACEroDVPvXr10meffRbssQAAAIS8gGaeEhIStHz5cv31r39Vly5dymxGaRiGnnnmmaAMEAAAIJQEFJ7Wrl2rVq1aSZIyMjKUkZHh13/+3k8AAAANRUDh6W9/+1uwxwEAAFAv1PyjhwEAABoQwhMAAIAFhCcAAAALCE8AAAAWEJ4AAAAsIDwBAABYQHgCAACwgPAEAABgAeEJAADAAsITAACABYQnAAAACwhPqFGmYSjP7dWJM0XKc3tl8tBoAEA9F9CDgYGq8BiG0tJ3aOu+47625IRYTRieKLtp1uHIAAAIHDNPqBFmOcFJkrbuPa60VTuYgQIA1FuEJ9SI/GJPmeBUauve48ov9tTyiAAACA7CE2pEXoG7Wv0AAIQqwhOCzmMYKnJ7Kzwm0sVyOwBA/UR4QlCVrnXakXFCSV1jyz0mOSFWEWH2Wh4ZAADBQXhCUJWudVqz/oCGDri0TIAq/bSdwaftAAD1FPdOEFSla5kKijx6YflmDR3YWTcPvFRFxV45w2xqFR3JNgUAgHqN8ISgOnctU0GRR++u2+fXv3DKYElsUwAAqL+4bYegigizKzmBtU4AgIaL8ISgMkxTE4YnlglQrHUCADQU3LZD0NlNU/cPT1R+sUd5BW5FuhyKCLMTnAAADQLhCTXCME1FOmyKbOosaSA4AQAaiHp32+7QoUNKTk7WqlWrfG27d+/WyJEj1bt3bw0ePFhLly6twxECAICGrF6Fp+LiYk2ZMkV5eXm+tpycHI0ePVodO3ZUenq6Jk2apPnz5ys9Pb0ORwoAABqqenXb7qWXXlKTJk382t599105nU7Nnj1bDodDnTt3VmZmphYvXqwRI0bU0UgBAEBDVW9mnjZt2qQVK1bo+eef92vfvHmzUlJS5HD8mAP79eunQ4cOKTs7u7aHCQAAGrh6EZ5yc3M1bdo0PfbYY2rTpo1f39GjRxUXF+fX1qpVK0nSkSNHam2MAACgcagXt+1mz56t3r1766abbirTV1BQIKfT6dcWHh4uSSosLKzW+zocwcuWdrvN73dUDXWzjpoFhrpZR80CQ92sC7WahXx4Wr16tTZv3qw///nP5fa7XC4VFRX5tZWGpsjIyIDf12YzFB3dpPIDLYqKigj6ORsD6mYdNQsMdbOOmgWGulkXKjUL+fCUnp6u7OxsDR482K/98ccf19KlS9W2bVtlZWX59ZV+37p164Df1+s1lZubV/mBVWS32xQVFaHc3Hx5PN6gnbeho27WUbPAUDfrqFlgqJt1Va1ZVFRErcxOhXx4mjNnjgoKCvzafvazn2ny5Mm64YYb9L//+79655135PF4ZLeXPDdtw4YN6tSpk1q0aFGt93a7g39RezzeGjlvQ2Mahm+H8twCt1wOm0z+J2MJ11pgqJt11Cww1M26UKlZyIenC80etWjRQu3atdOIESO0ZMkSzZw5U3fffbd27NihN954Q0888UQtjxTB4jEMpaXv0NZ9x31tpc/Gs7NTOQCgjoXGyqtqaNGihZYsWaJDhw5p2LBhWrhwoaZNm6Zhw4bV9dAQALOc4CRJW/ceV9qqHTINo45GBgBAiZCfeSrP3r17/b5PTEzUihUr6mg0CKb8Yk+Z4FRq697jyi/2KDKIn4IEAMAq/hZCSMkrcFerHwCAmkZ4QkiJdIVV0l8yWWoahvLcXp04U6Q8t5fbeQCAWlMvb9uhYfIYhvZkZiupa6y27y976y45IVYRYXZ5JBaUAwDqDDNPCAmlC8WXvL9TQwdcqqSusX79peHIUNngJLGgHABQe5h5Qkg4d6H4C8s3a+jAzrp54KUqKvbKGWZT25ZNZTdN5bm9LCgHANQpwhNCwrkLwQuKPHp33T6//t/ef5VaNnVWaUF5ZFNnhccAAFAd/BMdIaF0IfiF+8OqeBz/HgAA1CzCE0JCRJhdyQmx5fYlJ8SqSbi9SsdFhNlrbIwAAEiEJ9Sx0i0Hsn8o1Nibeur+XybJ5fwxACUnxGryrcmy/2cduGGamjA8sUyA8i0o59N2AIAaxj0O1JkLPcPuxYcG64ezhYoId6hJuEMtm0coJ+es7xi7aer+4Ym+BwdHuhyKCLMTnAAAtYKZJ1RZRRtTWt20sqJn2L3ypx2KaRquSIfNN+N0PsM0FemwqWVTpyIdNoITAKDWMPOEKrnQLNHE4YkyZX3TSp5hBwCor/jbCZWqaJZoW8aJgDat5Bl2AID6ivCESlU0SxQT5ap0Bqk8bDkAAKivCE+oVEWzQEXF3oBey5YDAID6in/eNxKmYQT86bQLzQK5nHa1ionQrLFX+B6jsiczR2vWH1BBkafC15ZuOZC2aoe27i27VooF4ACAUEV4agQutNi7ogXd5yqdJTo35Licdk0d2Vdvfrhb2845b1LXWE0d2VcvLN+s7p1iSmaQLvAebDkAAKiPuG3XwFW02LuiBd3nKm9jyqEDO2vN5wf9gpMkbd9/XGs+P6i7b+5ZpRkkthwAANQ3zDw1cMHaEuD8WSJXuKPMw3tLbd9/XONu7lmlWS0AAOobZp4auGBuCWCYpiLC7Ip0OXQ2v7iS81bcDwBAfUV4auCCuSWAxzC0MH2H7p/zqfILKw5dbDUAAGioCE8NXLC2BDh/7dSezBwldWWrAQBA40N4auDKW+wtWd8S4Py1U2vWH9DQAZeWCVBsNQAAaOi4t9IIBGNLgPPXRhUUefTC8s0aOrCzbh54qSLDw9Q0kq0GAAANH+GpkSjdEiCyqbOkwUrAMQxFlLOGqaDI4/vE3cIpV0sylf1DIfs1AQAaNMITKuQ1DGWdKtB3x88oqWustu8vu+1BckKs9mSe1MKV2/3aqroJJwAA9QlrnnBBpmFoW8YJrVi3T0vX7LzgGqdfpsZryfs7/dqtbMIJAEB9wswTLii/2KOYKJdvtuncNU6lz7Jr27KJHpj3me9ZdueysgknAAD1BeGpkTn3AcFNIhwKD3OooMhd7kLyvAK3ioq9vteeu8ap1LMT+pcbnErlFbh/XGcFAEADQHhqRM59QHDpg33XfH7Qbx3TuWuVIl0OnalkJ/EmEWEV9rNZJgCgoeF+SiNx/iaXpQ/2PX8B+LlrlVxOh7JPF1S4GWZkuCMom3ACAFBfEJ4aCNMwlOf26sSZIuW5vZJh+LWdLfLf5LJbh+hyPzkn/bhWqbDYrZbNI3TbtfFlF4rHx+reYYmyeb1B2YQTAID6gnsqDYDnvFkll9OuWWP7aeUn+3xtM+5I8XvNuWuZylO6Kebzb27S8Ku76M5fdJfUQwWFbjnshrbuP67cs4Vq0cQZlE04AQCoLwhP9dz5t+OkkltyK9bt85tZcob5TzKe//35XOEO5Re4NW1UX+3JzNGjaf8sszC8f682vq+rtQknAAD1SL24bXfq1CnNmjVLAwcOVJ8+fXT77bdr8+bNvv7du3dr5MiR6t27twYPHqylS5fW4Whr1/nPnJPKvyV3/oN8K3qwb1LXWP1j+xFNf/kf+s3SjdqbmaOpI/vK5fxx/RLrmQAAjVW9CE8PPfSQtm/frrlz5+q9997TZZddprFjx+rAgQPKycnR6NGj1bFjR6Wnp2vSpEmaP3++0tPT63rYteL8Z85J5d+SO/9Bvhd6sG9S11gNHXCp1qw/IJfTrluvjdfNAy+VDOk346/UrdfG64rLWrOeCQDQaIX8bbvMzEz985//1B//+Ef16dNHkjRz5kytX79eH3zwgVwul5xOp2bPni2Hw6HOnTsrMzNTixcv1ogRI+p49DWvvK0Ayrsld+6DfO+6sYeyTuapRTOXbhvS1bfpZesWkdrw5fd6YXnJrF7pVgbn7u2UnBCr+3jsCgCgEQv58BQdHa1XX31VPXv29LUZhiHTNHX69Gnt3LlTKSkpcjh+/FH69eunV155RdnZ2WrRokVdDLvWRITZlZwQq617f7xNV3pL7vxbdwVFHu3NzPF9/+H/HfY7ZsYdKb6gdOu18RfcymDRqh26n5knAEAjFfLhKSoqSoMGDfJr++ijj/T111/rqquu0rx58xQfH+/X36pVK0nSkSNHqhWeHEF8rIjdbvP7PZgmDE9U2qodvgC1Zv0BzRrbTzZbSdhxOe0aOrCzEru0lM0wVFjsUbOmTv31i8O69dp4desQraJir+JaRJaEpvUH1K1DdJndxEuVbGXgVZSr5tc81WTdGipqFhjqZh01Cwx1sy7Uahby4el8W7Zs0aOPPqprrrlGqampevbZZ+V0+j/+Izw8XJJUWFgY8PvYbIaio5tUa6zliYqKCPo5pZJbbKfPFOpsfrGaRISpWdNwTR3ZVydO5cswDC1bs9P/9lt8rJ66r7/e+GCXX3tS11hNHdlXbk/Fs0oFRW51aBNVIz9LeWqqbg0ZNQsMdbOOmgWGulkXKjWrV+Fp3bp1mjJlipKSkjR37lxJksvlUlFRkd9xpaEpMjIy4Pfyek3l5uYFPtjz2O02RUVFKDc3Xx5PxXssBapJmE1NwkqCo7uw5LEqToddi1bt8Lv95nLa1a1TjAqLPBp+dRf993XdZMrU5t3HtOrvGVoj/WdfpwtzOR3KyTlbIz/HuWqjbg0NNQsMdbOOmgWGullX1ZpFRUXUyuxUvQlPy5cv19NPP60hQ4Zozpw5vtmmuLg4ZWVl+R1b+n3r1q2r9Z5ud/Avao/HWyPnvRC3xywTnKaNKlkI/se/7PW1J3WN1W3XxqvrJdF6/s1NcthtSo6PLbMNglS6TYGtVn+O2q5bQ0DNAkPdrKNmgaFu1oVKzULj5mEl/vCHP+jJJ5/Ur371K7344ot+t+lSUlK0ZcsWeTw/buC4YcMGderUqcEvFq+KvAL/B/uWPtNu23mhaPv+41qxbp9OnMrX0IGdlX06XzdeVXYrAx67AgBo7EJ+5unQoUN65plnNGTIEI0fP17Z2dm+PpfLpREjRmjJkiWaOXOm7r77bu3YsUNvvPGGnnjiiTocdeiIcIX5fV/RQvDt+4/r5oGXqkUzl2KbR8owTI27uae8pqmCQh67AgCAVA/C01/+8hcVFxdr7dq1Wrt2rV/fsGHD9Nxzz2nJkiV6+umnNWzYMMXGxmratGkaNmxYHY247nltNuUXumUYhvZmnvTbtqCyZ9oVFXsVFmZTRJjtnJBkqGkYj10BAECqB+Hp3nvv1b333lvhMYmJiVqxYkUtjSi0uQ1DL6/cru37j2vW2Cu05P2dmjqyr6SSmaXKnmnnDLMpNjqS2SUAAC6gXqx5QtV4bTa9/N4Ov1mm0p3FEzpEa9bYKxTVJFzJCRd+pt3J3AJFVhKwAABozEJ+5gk/Mg1D+cUe5RWUXX9kGobyi9y6fUi8xg/rJbfbK+9/+gqKPL51TqWftpMpv0/SlX7arlVzF7NOAABUgPBUT3gMQ2npO/wCT3JCrCYOT5QpKS19h3YfPqmpI/vqj2v3afv+47r12vgyj2kpKPLot29t1j239NIdN/RQfqFbrnCH7DZDTV0OGd66/wgoAAChjPBUD5jlBCep5DEp2zJO6J/bj2j34ZOaMrKvwp123XBlR/3q+m5y2A31iY/Vrdd01faME1qz/oAKijzq3ilGzZqG65G0f6igyPPj9gMEJwAAKkV4qgfyiz3lblYpSTFRLt+M05//4b9/U1LXWA0dcKleWL5Z3TvGaO4Dg3TqhwLFNItQVnaenhj3UzWJYPsBAACsIDyFONMwdDbfXW6fy2lXs6bhmjN5oJau2VnuxpdSycaY767bp8Wrv1TX9tHam5mjhA7R6tutlSIdNrYfAADAAj5WFcI8hqGF6Tt09rxdwqWS4DTjjhQt/2i3snLyLjgztX3/cXXrEC2pZIF4tw7RvrZIF9kZAACrCE8h6tx1Tnsyc8o8JmXowM5avf6Atu47XqWNL8//2pQUEWYP+rgBAGjomHoIUeeuc1qz/oCm35Giq5LaqkUzl4qKvYprEak16w/o1mvj1bpFpFxOu4YO7KxuHaJVVOyVM8ymPZk5WrP+gN/GmKVft2IjTAAAAkJ4ClF5Bf7rnEzT1D93HNG2fcflcto1++5+mjqyr9Z8flAOu6FZY/tpxbp9fs+tS+oaq1lj+2nnwROSpOT4WO3JzFFyQmzJRpiEJwAALCM81aIf8oqUW+BRXkFxpQ/ZjWri1KyxV6io2KtWMRF688PdvgXhw6/uomYXhcvjNTX86i5q1TxCr67+0m8/J6lkvZPNkLp1ilFS11jdM6yXlq35SvcOS2TWCQCAABGeakmhx9S85Zu1da//JpcThifKfl6Q8RiGXln1475Os8Ze4QtOLqdd/RPb6tU/fenXf6EF41v3Hdcdv+ihmItckqQresYpzFDJoicAAGAZ4akWVLTJZdqqHbp/+DkzQYah7RkndNOAS3VD/05q06KJTNPUM/f1V5OIMEWE27XovHNVtmD85OkCxUS5dDQ7T0ldWnK7DgCAaiA81YKKNrncuve48os9JfstSSoypc+3HdHezJKNLxe/v9N3O87ltOu5+68qcy5nJQ/yvSgyTLNe3aA5kweWmeUCAADWsFVBLTh/8Xd5/aZhqFjSK6t2aPv+4xo6sLPWfH7Qbx3T0IGdlX2qoMzry9vKoFRyfKw278lS904xiqgkZAEAgMrxt2ktqGwzyghXmF59f6fyCn6coSrdzPJc3TpEyzDKvn7N+gMaOuDSMgEqqWus7r65pzK/P13y7DpmnQAAqDZu29WCiDC7khNi/RaLl0pOiNXezJPq0LaZTub+OKtU3jqmomKvDh45raSusX7BqqDIoxeWb9bdN/fUr65L0A95xbooMkxfH/tBDruhe4b2JDgBABAkhKdaYJimJg5P1LaME4qJcvk2sTyZW6DEzi01ee6nmjaqr99rylvH5Ayzac36A5o6suTYcwNUQocYde8Yo9c/2KXrf9pR6X/fr7uH9ixZ40RwAgAgaAhPtcSU9M8dR8psVXDZpS0kSW6PqZbNXerdNVbb9v/4SJZzA9KezBwldIjRC8s3a+jAzrp54KV+QcxhN3TnL3rIMExmmwAAqCGEp1pQ0VYFr67+UkMHdlbL5i6998l+3X1LTy1ds1Of/fsbPXHPlTpxKl9n8orlDLNp/7endPuQ+DI7iffuGqv7RiQqzJDCHJJkMNsEAEANITzVgsq2KhhxdVd5vF5dk9Jeb/7vLvWOb6l7hycq7b0dfjNPyQmxGtS7nXrHt9RNAy5VRLhDTSPD5ApzyG5I8la83xMAAKg+Pm1XCyrbqsAZZlPzJuFqflG4bhnURVf0aKNF6TvKfNpu697jWrTqS7VrFaXfLN0om81QyYfvTIITAAC1hJmnWlDRVgUup11NI5x+t/XOfRzL+bbvP667buwhSQoPs8trio0vAQCoRcw81YLSrQrKM3ZoTy1e/aWlx63kF7iV1DVWJ04XqKCw4lktAAAQXISnWmCYpiYMTywToJITYtXl4ubaffikbr8uQb+9/yo9c19/tY1toluvjZfLaS/3fJEuhyaMSNTCd7dWugEnAAAILv7mrSXhdkNTR/bV8Zw8Hc3OU+uYSDnsNh09eVbTRvXVms8P6o9/2es7PqlrrKaO7KsXlm9WQZHHrz3S5dA/tn+nTu2aKSLMzifrAACoRcw81RKPKZ0+UyhJyjyaK4fDkMNu6OLYplrz+cEya5y27z+uNZ8f1NCBnX1tyfGxmjAiUcey87U3M4dHrgAAUAeYeaoFHsNQ2srt2rrvuP77ugQNSG4nm2FoyeqdGvnz7pUuDu/dNVYFRW61bdlUXtOrmGZONsEEAKCOMPNUw87dINPltJc83FfSjowTuv26BJ04nV/h649l5yn3bJF+s3SjTp8t1Nsf75HLYSc4AQBQRwhPNax0g0yX064Zd6Tof/9xSB6PqX9sO6JTPxT+Z5+mC3OG2XzPuQsPs+sf279XfrGnklcBAICaQniqYaUbZA4d2Fmr1x9Qh7bNtPj9ndq+/7iKir3ak5mj3vHlb2OQ1DVW2acLtCczR8kJJVsTnHtOAABQ+whPNax0K4FuHaK1bd9x3+9SyazSmvUHNHTApUo+L0AldY3VbdfGq2XzCGV+f1p3D+2lhe9u9TsnAACoffwtXMNKN8gs3fjy3A0w92TmKKFDjH771mYNu7qLbv9ZgtweU5Eux392DzdlytTPr+yomYv+oVNnipScEMv2BAAA1CHCUw0zTFPjhyXqxKmSheGl65ckac36A5o6sq/WSPrjX/b69nlKTojVfcMT9e5f9+rvW77zHZ+cEMv2BAAA1LEGEZ68Xq8WLlyolStXKjc3Vz/5yU/0+OOPq0OHDnU9NEnSD2cLFeFyKDkhVnsyc5TUNVbb9x9XQZFHLyzfrKEDO+vmgZfKlNS8abiaNXHK5vVq5M+6acTVXZVX4Faky6GIMD5lBwBAXWsQa57S0tL0zjvv6KmnntKKFStkGIbGjRunoqKiuh6aJCki3KEnl3yh8bck6tB3pzV0wKVK6lqyxqmgyKN31+3T++sPKsLpUFRkmGzeklt7hmkq0mFTy6ZORTpsBCcAAEJAvZ95Kioq0rJlyzR16lQNGjRIkjRv3jwNGDBAa9eu1S9+8Ys6HmHJuqdO7Zrpn19+p8t7xsluMzTq59015qYeyi/0KDzMLpvNUFOXQ4a34ocCAwCAulXvw9OePXt09uxZ9evXz9cWFRWlHj16aNOmTSERnkofDLxkzU797IqO+tNnB7R9/4+7ivvWMhGcAAAIefU+PB09elSS1KZNG7/2Vq1a6fvvv6/WuR2O4N3VDLfb9D//1UenfijQuJt7ymuaKih0K9IVpibhdtkNSZVumdn42O02v99ROWoWGOpmHTULDHWzLtRqVu/DU37+fz7F5nT6tYeHh+v06dMBn9dmMxQd3aRaYyvPRZHOyg9CGVFREXU9hHqHmgWGullHzQJD3awLlZrV+/Dkcrkklax9Kv1akgoLCxUREXiRvV5Tubl51R5fKbvdpqioCOXm5svj4fZcVVE366hZYKibddQsMNTNuqrWLCoqolZmp+p9eCq9XZeVlaX27dv72rOystStW7dqndvtDv5F7fF4a+S8DR11s46aBYa6WUfNAkPdrAuVmoXGzcNq6Natm5o2baqNGzf62nJzc7Vr1y717du3DkcGAAAaono/8+R0OjVy5EjNmTNHMTExateunV544QXFxcVpyJAhdT08AADQwNT78CRJkydPltvt1mOPPaaCggKlpKRo6dKlZRaRAwAAVFeDCE92u11Tp07V1KlT63ooAACggav3a54AAABqE+EJAADAAsITAACABYQnAAAACwzTNM26HkQoMk1TXm9wS2O329hNNgDUzTpqFhjqZh01Cwx1s64qNbPZDBlGzT8nlvAEAABgAbftAAAALCA8AQAAWEB4AgAAsIDwBAAAYAHhCQAAwALCEwAAgAWEJwAAAAsITwAAABYQngAAACwgPAEAAFhAeAIAALCA8AQAAGAB4QkAAMACwlMt8Hq9WrBggQYMGKCkpCSNGTNGmZmZdT2sGvPdd98pISGhzK+VK1dKknbv3q2RI0eqd+/eGjx4sJYuXer3+qrUKxjnCBVpaWkaNWqUX1uo1Kiyc9Sl8ur2yCOPlLnuBg4c6OtvjHU7deqUZs2apYEDB6pPnz66/fbbtXnz5iqPtTHWTKq8blxrZWVnZ2vq1Knq16+fkpOTdc899ygjI6PKY61XNTNR41566SXzpz/9qfnpp5+au3fvNseMGWMOGTLELCwsrOuh1YhPPvnE7NWrl3ns2DEzKyvL9ys/P988efKkecUVV5gzZ840MzIyzPfee8/s1auX+d577/leX1m9gnGOUPHaa6+ZCQkJ5siRI31toVKjqpyjrpRXN9M0zWHDhplz5871u+6ys7N9/Y2xbqNHjzaHDh1qbtq0yTxw4ID55JNPmomJiWZGRgbXWgUqqptpcq2V55e//KV52223mTt27DAzMjLMSZMmmf379zfz8vIa3LVGeKphhYWFZnJysvmHP/zB13b69GkzMTHR/OCDD+pwZDVn0aJF5tChQ8vt+/3vf28OGDDALC4u9rX97ne/M6+77jrTNKtWr2Cco64dPXrUHDt2rNm7d2/z+uuv9wsBoVKjys5RFyqqm9vtNnv16mWuXbu23Nc2xrodPnzYjI+PN7ds2eJr83q95pAhQ8wXX3yRa+0CKqsb11pZJ0+eNB988EFz3759vrbdu3eb8fHx5vbt2xvctcZtuxq2Z88enT17Vv369fO1RUVFqUePHtq0aVMdjqzm7N27V126dCm3b/PmzUpJSZHD4fC19evXT4cOHVJ2dnaV6hWMc9S1r776Ss2aNdOaNWuUlJTk1xcqNarsHHWhorodPnxYhYWF6ty5c7mvbYx1i46O1quvvqqePXv62gzDkGmaOn36NNfaBVRWN661sqKjozV37lx17dpVknTixAktXbpUcXFx6tKlS4O71ghPNezo0aOSpDZt2vi1t2rVSt9//31dDKnG7du3T9nZ2frv//5vXXnllbr99tv1+eefSyqpR1xcnN/xrVq1kiQdOXKkSvUKxjnqWmpqqn73u9/pkksuKdMXKjWq7Bx1oaK67du3T4Zh6I033lBqaqquvfZaPfnkk/rhhx8kVe3PYkOrW1RUlAYNGiSn0+lr++ijj/T111/rqquu4lq7gMrqxrVWsV//+tfq37+/Pv74Yz399NOKjIxscNca4amG5efnS5LfH0JJCg8PV2FhYV0MqUYVFRXp8OHDOnPmjB544AG9+uqr6tWrl8aNG6cNGzaooKCg3FpIUmFhYZXqFYxzhLJQqVFl5wg1+/fvl81mU7t27fT73/9e06dP12effaYJEybI6/VSN0lbtmzRo48+qmuuuUapqalca1V0ft241ip25513Kj09XUOHDtXEiRP11VdfNbhrzVH5IagOl8slqSRUlH4tlfxHioiIqKth1Rin06lNmzbJ4XD4LtCePXvqwIEDWrp0qVwul4qKivxeU3rBRkZGVqlewThHKAuVGlV2jlAzadIk3XXXXYqKipIkxcfHKzY2Vrfddpu+/PLLRl+3devWacqUKUpKStLcuXMlca1VRXl141qrWOmyjSeffFLbtm3T8uXLG9y1xsxTDSudPszKyvJrz8rKKjN12FBERkaWSfbx8fE6duyY4uLiyq2FJLVu3bpK9QrGOUJZqNSosnOEGsMwfH+ZlYqPj5dUMlXfmOu2fPlyTZo0SQMHDtTixYt9f7FwrVXsQnXjWisrOztbH3zwgTwej6/NZrOpc+fOvjE3pGuN8FTDunXrpqZNm2rjxo2+ttzcXO3atUt9+/atw5HVjD179ig5OdlvPxRJ2rlzp7p06aKUlBRt2bLF7w/Yhg0b1KlTJ7Vo0aJK9QrGOUJZqNSosnOEmocfflhjx471a/vyyy8llfxLuLHW7Q9/+IOefPJJ/epXv9KLL77o9w8brrULq6huXGtlZWVl6eGHH9a//vUvX1txcbF27dqlzp07N7xrzdJn8xCQuXPnmpdffrm5bt06374TP/vZz0Juz6Fg8Hg85i9/+UvzxhtvNDdt2mRmZGSYzzzzjNmzZ09zz5495okTJ8yUlBRz+vTp5v79+8309HSzV69e5qpVq3znqKxewThHKJk+fbrfR+5DpUZVOUddOr9uf/vb38yEhAQzLS3NzMzMND/99FMzNTXVfOihh3zHNLa6HTx40LzsssvMiRMn+u1HlJWVZebm5nKtXUBldeNaK8vr9Zpjxowxr7vuOnPTpk3m3r17zQcffNBMSUkxv/vuuwZ3rRGeaoHb7TZ/+9vfmv369TN79+5tjhs3zvzmm2/qelg1Jjs723zkkUfM/v37m7169TJvu+02c9OmTb7+7du3m7feeqvZs2dP8+qrrzbfeustv9dXpV7BOEeoOD8EmGbo1Kiyc9Sl8ur28ccfm7fccouZmJho9u/f33zuuefMgoICX39jq9uiRYvM+Pj4cn9Nnz69SmNtbDUzzarVjWutrNzcXPPxxx83+/fvbyYmJppjxozx2/epIV1rhmmaZtXnqQAAABo31jwBAABYQHgCAACwgPAEAABgAeEJAADAAsITAACABYQnAAAACwhPAHAB7OQCoDyEJwAhKzU1VTNmzKj1983NzdX06dP9HjM0atQojRo1qtbHAiD0EJ4A4Dy7d+/W6tWr5fV663ooAEIQ4QkAAMACwhOAeqGwsFC//e1vNWjQIPXs2VM33XSTPvzwQ79jUlNTtWDBAj3//PO68sorlZiYqLFjx+rQoUN+x/3pT3/SDTfcoF69emno0KHasGGDevTooVWrVmnjxo264447JEl33HGH36060zS1ePFiDR48WImJibrtttv05Zdf1vwPDyCkEJ4AhDzTNDVx4kS98847Gj16tBYtWqTk5GQ9+OCDWr16td+xb775pg4ePKhnn31WTz31lHbu3Om3bmr16tWaMWOG+vTpo7S0NF133XWaMGGCPB6PJOmyyy7TrFmzJEmzZs3S448/7nvtli1btHbtWv3617/W888/r2PHjunee++V2+2u+SIACBmOuh4AAFTm//7v//T5559r3rx5uuGGGyRJAwYMUH5+vubMmaMbb7xRDkfJ/86ioqKUlpYmu90uSfr666/10ksvKScnR9HR0Zo/f76uvvpqPfXUU77zhIWF6Xe/+50kqWnTpurSpYskqUuXLr6vJcnpdOrVV19V8+bNJUlnzpzRY489poyMDHXr1q1WagGg7jHzBCDkbdiwQYZhaNCgQXK73b5fqampOn78uPbv3+87tlevXr7gJElxcXGSpPz8fGVmZurIkSO6/vrr/c7/i1/8okrj6NKliy84SdLFF18sSfrhhx8C/dEA1EPMPAEIeadOnZJpmurTp0+5/VlZWerevbskKSIiwq/PZiv5N6LX69XJkyclSS1atPA7JjY2tkrjiIyMvOC5ATQehCcAIe+iiy5SZGSk3nzzzXL7O3ToUKXzlM5CZWdn+7Wf/z0AVITbdgBC3uWXX668vDyZpqlevXr5fu3fv18vv/xylRdsx8XFqX379lq7dq1f+1/+8he/78+97QcA52PmCUDIGzRokFJSUjRhwgRNmDBBnTt31o4dO/TSSy/pqquuUkxMTJXOYxiGJk+erClTpujxxx/XkCFDtGfPHr388suSfrwNd9FFF0mSPv30UzVr1ozF4AD8EJ4AhDybzaZXX31V8+fP1yuvvKLs7Gy1bt1ad911lyZOnGjpXDfddJPy8vK0dOlSpaenq2vXrpo5c6ZmzpzpW9PUtWtX3XjjjXr77bf1+eef64MPPqiJHwtAPWWYPPkSQCPywQcfqEePHrr00kt9bZ9++qnGjx+v999/n1kmAJUiPAFoVO655x4dOHBADzzwgNq0aaPDhw9rwYIF6tChg9566626Hh6AeoDwBKBRycnJ0e9+9zutX79eJ0+eVMuWLXXddddp8uTJatKkSV0PD0A9QHgCAACwgK0KAAAALCA8AQAAWEB4AgAAsIDwBAAAYAHhCQAAwALCEwAAgAWEJwAAAAsITwAAABYQngAAACz4/5Dh4nhtE6NUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#How does reading time relates with article length?\n",
    "\n",
    "articles['length']=articles['text'].apply(lambda x: len(x))\n",
    "\n",
    "sns.scatterplot(data=articles,x='length',y='reading_time')\n",
    "print('Correlation Coefficient:',round(np.corrcoef(articles['length'],articles['reading_time'])[0,1],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading increases as length of the article increases which is pretty logical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Abhay Pawar</td>\n",
       "      <td>Machine learning models for 100% better return...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Adam Geitgey</td>\n",
       "      <td>Machine Learning is Fun! Part 4: Modern Face R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Adam Geitgey</td>\n",
       "      <td>Machine Learning is Fun! Part 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Adam Geitgey</td>\n",
       "      <td>Machine Learning is Fun Part 6: How to do Spee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Adam Geitgey</td>\n",
       "      <td>Machine Learning is Fun! Part 3: Deep Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>Yueh</td>\n",
       "      <td>2018  &amp; : KOKO COMBO icash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>allen farrington</td>\n",
       "      <td>Bitcoin Is Venice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>allen farrington</td>\n",
       "      <td>Gauge Theory Does Not Fix This</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>sunil kumar</td>\n",
       "      <td>Advantages and Disadvantages of Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>zawadi</td>\n",
       "      <td>I need more iron</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                              title\n",
       "43        Abhay Pawar  Machine learning models for 100% better return...\n",
       "30       Adam Geitgey  Machine Learning is Fun! Part 4: Modern Face R...\n",
       "86       Adam Geitgey                    Machine Learning is Fun! Part 2\n",
       "101      Adam Geitgey  Machine Learning is Fun Part 6: How to do Spee...\n",
       "33       Adam Geitgey  Machine Learning is Fun! Part 3: Deep Learning...\n",
       "..                ...                                                ...\n",
       "151              Yueh                        2018  & : KOKO COMBO icash \n",
       "105  allen farrington                                  Bitcoin Is Venice\n",
       "139  allen farrington                     Gauge Theory Does Not Fix This\n",
       "91        sunil kumar  Advantages and Disadvantages of Artificial Int...\n",
       "179            zawadi                                   I need more iron\n",
       "\n",
       "[208 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.sort_values(by='author')[['author','title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'She would like to know how I would done that! She is going to the park and I do not think I will be home for dinner.They Are going to the zoo and she will be home for dinner'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contractions.fix(\"She'd like to know how I'd done that! She's going to the park and I don't think I'll be home for dinner.Theyre going to the zoo and she'll be home for dinner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles['text']=articles['text'].apply(lambda x: contractions.fix(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    \"it was the best of times\",\n",
    "    \"it was the worst of times\",\n",
    "    \"it was the age of wisdom and the age of foolishness\"\n",
    "]\n",
    "\n",
    "features=[]\n",
    "\n",
    "for sent in corpus:\n",
    "    features+=sent.split()\n",
    "    \n",
    "features=set(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>best</th>\n",
       "      <th>age</th>\n",
       "      <th>times</th>\n",
       "      <th>and</th>\n",
       "      <th>it</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>was</th>\n",
       "      <th>of</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>it was the best of times</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it was the worst of times</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it was the age of wisdom and the age of foolishness</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    the  best  age  times  \\\n",
       "it was the best of times                              1     1    0      1   \n",
       "it was the worst of times                             1     0    0      1   \n",
       "it was the age of wisdom and the age of foolish...    2     0    2      0   \n",
       "\n",
       "                                                    and  it  wisdom  was  of  \\\n",
       "it was the best of times                              0   1       0    1   1   \n",
       "it was the worst of times                             0   1       0    1   1   \n",
       "it was the age of wisdom and the age of foolish...    1   1       1    1   2   \n",
       "\n",
       "                                                    foolishness  worst  \n",
       "it was the best of times                                      0      0  \n",
       "it was the worst of times                                     0      1  \n",
       "it was the age of wisdom and the age of foolish...            1      0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab=set(\" \".join(corpus).lower().split(' '))\n",
    "\n",
    "bow=[]\n",
    "\n",
    "for sent in corpus:\n",
    "    d=dict([(v,0) for v in vocab])\n",
    "    for word in word_tokenize(sent.lower()):\n",
    "        d[word]+=1\n",
    "    bow.append(d)\n",
    "\n",
    "pd.DataFrame(bow,index=corpus)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>it</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   it  was\n",
       "0   2    7\n",
       "1   5    8"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([{'it':2,'was':7},{'it':5,'was': 8}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'the': 1,\n",
       "  'best': 1,\n",
       "  'age': 0,\n",
       "  'times': 1,\n",
       "  'and': 0,\n",
       "  'it': 1,\n",
       "  'wisdom': 0,\n",
       "  'was': 1,\n",
       "  'of': 1,\n",
       "  'foolishness': 0,\n",
       "  'worst': 0},\n",
       " {'the': 1,\n",
       "  'best': 0,\n",
       "  'age': 0,\n",
       "  'times': 1,\n",
       "  'and': 0,\n",
       "  'it': 1,\n",
       "  'wisdom': 0,\n",
       "  'was': 1,\n",
       "  'of': 1,\n",
       "  'foolishness': 0,\n",
       "  'worst': 1},\n",
       " {'the': 2,\n",
       "  'best': 0,\n",
       "  'age': 2,\n",
       "  'times': 0,\n",
       "  'and': 1,\n",
       "  'it': 1,\n",
       "  'wisdom': 1,\n",
       "  'was': 1,\n",
       "  'of': 2,\n",
       "  'foolishness': 1,\n",
       "  'worst': 0}]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>and</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>it</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>was</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       and      best  foolishness        it        of       the  \\\n",
       "0  0.000000  0.000000  0.166667     0.000000  0.166667  0.166667  0.166667   \n",
       "1  0.000000  0.000000  0.000000     0.000000  0.166667  0.166667  0.166667   \n",
       "2  0.181818  0.090909  0.000000     0.090909  0.090909  0.181818  0.181818   \n",
       "\n",
       "      times       was    wisdom     worst  \n",
       "0  0.166667  0.166667  0.000000  0.000000  \n",
       "1  0.166667  0.166667  0.000000  0.166667  \n",
       "2  0.000000  0.090909  0.090909  0.000000  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "bow_rep = cv.fit_transform(corpus).todense()\n",
    "bow_rep\n",
    "pd.DataFrame(data=bow,columns=cv.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>best</th>\n",
       "      <th>age</th>\n",
       "      <th>times</th>\n",
       "      <th>and</th>\n",
       "      <th>it</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>was</th>\n",
       "      <th>of</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>it was the best of times</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it was the worst of times</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it was the age of wisdom and the age of foolishness</th>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         the      best  \\\n",
       "it was the best of times                            0.166667  0.166667   \n",
       "it was the worst of times                           0.166667  0.000000   \n",
       "it was the age of wisdom and the age of foolish...  0.181818  0.000000   \n",
       "\n",
       "                                                         age     times  \\\n",
       "it was the best of times                            0.000000  0.166667   \n",
       "it was the worst of times                           0.000000  0.166667   \n",
       "it was the age of wisdom and the age of foolish...  0.181818  0.000000   \n",
       "\n",
       "                                                         and        it  \\\n",
       "it was the best of times                            0.000000  0.166667   \n",
       "it was the worst of times                           0.000000  0.166667   \n",
       "it was the age of wisdom and the age of foolish...  0.090909  0.090909   \n",
       "\n",
       "                                                      wisdom       was  \\\n",
       "it was the best of times                            0.000000  0.166667   \n",
       "it was the worst of times                           0.000000  0.166667   \n",
       "it was the age of wisdom and the age of foolish...  0.090909  0.090909   \n",
       "\n",
       "                                                          of  foolishness  \\\n",
       "it was the best of times                            0.166667     0.000000   \n",
       "it was the worst of times                           0.166667     0.000000   \n",
       "it was the age of wisdom and the age of foolish...  0.181818     0.090909   \n",
       "\n",
       "                                                       worst  \n",
       "it was the best of times                            0.000000  \n",
       "it was the worst of times                           0.166667  \n",
       "it was the age of wisdom and the age of foolish...  0.000000  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Term Frequency\n",
    "\n",
    "corpus = [\n",
    "    \"it was the best of times\",\n",
    "    \"it was the worst of times\",\n",
    "    \"it was the age of wisdom and the age of foolishness\"\n",
    "]\n",
    "\n",
    "\n",
    "vocab=set(\" \".join(corpus).lower().split(' '))\n",
    "\n",
    "bow=[]\n",
    "\n",
    "for sent in corpus:\n",
    "    len_doc=0\n",
    "    d=dict([(v,0) for v in vocab])\n",
    "    for word in word_tokenize(sent.lower()):\n",
    "        d[word]+=1\n",
    "        len_doc+=1\n",
    "    for key,values in d.items():\n",
    "        d[key]=d[key]/len_doc\n",
    "    bow.append(d)\n",
    "\n",
    "df=pd.DataFrame(bow,index=corpus)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.0,\n",
       " 'best': 1.0986122886681098,\n",
       " 'age': 1.0986122886681098,\n",
       " 'times': 0.4054651081081644,\n",
       " 'and': 1.0986122886681098,\n",
       " 'it': 0.0,\n",
       " 'wisdom': 1.0986122886681098,\n",
       " 'was': 0.0,\n",
       " 'of': 0.0,\n",
       " 'foolishness': 1.0986122886681098,\n",
       " 'worst': 1.0986122886681098}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating Inverse Document Frequency\n",
    "\n",
    "len_corpus=len(corpus)\n",
    "\n",
    "len_words_corpus=[len(word_tokenize(x)) for x in corpus]\n",
    "\n",
    "num_docs=dict((v,0) for v in vocab)\n",
    "\n",
    "for word in vocab:\n",
    "    for sent in corpus:\n",
    "        if word in word_tokenize(sent):\n",
    "            num_docs[word]+=1\n",
    "for key,value in num_docs.items():\n",
    "    num_docs[key]=np.log((len_corpus)/value)\n",
    "num_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the</th>\n",
       "      <th>best</th>\n",
       "      <th>age</th>\n",
       "      <th>times</th>\n",
       "      <th>and</th>\n",
       "      <th>it</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>was</th>\n",
       "      <th>of</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>it was the best of times</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.183102</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it was the worst of times</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.067578</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it was the age of wisdom and the age of foolishness</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.199748</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    the      best       age  \\\n",
       "it was the best of times                            0.0  0.183102  0.000000   \n",
       "it was the worst of times                           0.0  0.000000  0.000000   \n",
       "it was the age of wisdom and the age of foolish...  0.0  0.000000  0.199748   \n",
       "\n",
       "                                                       times       and   it  \\\n",
       "it was the best of times                            0.067578  0.000000  0.0   \n",
       "it was the worst of times                           0.067578  0.000000  0.0   \n",
       "it was the age of wisdom and the age of foolish...  0.000000  0.099874  0.0   \n",
       "\n",
       "                                                      wisdom  was   of  \\\n",
       "it was the best of times                            0.000000  0.0  0.0   \n",
       "it was the worst of times                           0.000000  0.0  0.0   \n",
       "it was the age of wisdom and the age of foolish...  0.099874  0.0  0.0   \n",
       "\n",
       "                                                    foolishness     worst  \n",
       "it was the best of times                               0.000000  0.000000  \n",
       "it was the worst of times                              0.000000  0.183102  \n",
       "it was the age of wisdom and the age of foolish...     0.099874  0.000000  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for col in df.columns:\n",
    "    df[col]=df[col]*num_docs[col]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>and</th>\n",
       "      <th>best</th>\n",
       "      <th>foolishness</th>\n",
       "      <th>it</th>\n",
       "      <th>of</th>\n",
       "      <th>the</th>\n",
       "      <th>times</th>\n",
       "      <th>was</th>\n",
       "      <th>wisdom</th>\n",
       "      <th>worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>it was the best of times</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.441027</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it was the worst of times</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.441027</td>\n",
       "      <td>0.342496</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.579897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>it was the age of wisdom and the age of foolishness</th>\n",
       "      <td>0.617558</td>\n",
       "      <td>0.308779</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.308779</td>\n",
       "      <td>0.182370</td>\n",
       "      <td>0.364740</td>\n",
       "      <td>0.364740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182370</td>\n",
       "      <td>0.308779</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         age       and  \\\n",
       "it was the best of times                            0.000000  0.000000   \n",
       "it was the worst of times                           0.000000  0.000000   \n",
       "it was the age of wisdom and the age of foolish...  0.617558  0.308779   \n",
       "\n",
       "                                                        best  foolishness  \\\n",
       "it was the best of times                            0.579897     0.000000   \n",
       "it was the worst of times                           0.000000     0.000000   \n",
       "it was the age of wisdom and the age of foolish...  0.000000     0.308779   \n",
       "\n",
       "                                                          it        of  \\\n",
       "it was the best of times                            0.342496  0.342496   \n",
       "it was the worst of times                           0.342496  0.342496   \n",
       "it was the age of wisdom and the age of foolish...  0.182370  0.364740   \n",
       "\n",
       "                                                         the     times  \\\n",
       "it was the best of times                            0.342496  0.441027   \n",
       "it was the worst of times                           0.342496  0.441027   \n",
       "it was the age of wisdom and the age of foolish...  0.364740  0.000000   \n",
       "\n",
       "                                                         was    wisdom  \\\n",
       "it was the best of times                            0.342496  0.000000   \n",
       "it was the worst of times                           0.342496  0.000000   \n",
       "it was the age of wisdom and the age of foolish...  0.182370  0.308779   \n",
       "\n",
       "                                                       worst  \n",
       "it was the best of times                            0.000000  \n",
       "it was the worst of times                           0.579897  \n",
       "it was the age of wisdom and the age of foolish...  0.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer()\n",
    "tf_idf_rep = tf_idf_vectorizer.fit_transform(corpus).todense()\n",
    "df = pd.DataFrame(tf_idf_rep)\n",
    "df.columns = tf_idf_vectorizer.get_feature_names_out()\n",
    "df.index = corpus\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc226e29de9e4b12950f45869e88806c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'CountVectorizer' object has no attribute 'get_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[137], line 61\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# create dataframe\u001b[39;00m\n\u001b[1;32m     60\u001b[0m bow_features_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(bow_features)\n\u001b[0;32m---> 61\u001b[0m bow_features_df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m count_vectorizer\u001b[38;5;241m.\u001b[39mget_feature_names() \u001b[38;5;66;03m# Get output feature names for dataframe columns.\u001b[39;00m\n\u001b[1;32m     62\u001b[0m bow_features_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTITLE\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m articles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     63\u001b[0m bow_features_df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m articles[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CountVectorizer' object has no attribute 'get_feature_names'"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "\n",
    "\n",
    "def process_sentence(sentence, nlp_object):\n",
    "    # Convert to lowercase\n",
    "    sentence = sentence.lower()\n",
    "\n",
    "    # Exapnding contractions\n",
    "    sentence = contractions.fix(sentence)\n",
    "\n",
    "    # Lemmatization and removing stopwords\n",
    "    doc = nlp_object(sentence)\n",
    "    sentence = \" \".join([token.lemma_ for token in doc if not token.is_stop])\n",
    "\n",
    "    # Remove punctuation\n",
    "    for p in string.punctuation:\n",
    "        sentence = sentence.replace(p, \" \")\n",
    "    sentence = re.sub(r\"\\s+\", \" \", sentence) # Replace all whitespace characters with space\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "# tqdm to see real time progress\n",
    "tqdm.pandas()\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm') # English pipeline optimized for CPU\n",
    "\n",
    "def process_article(article_text, nlp_object):\n",
    "    processed_article_sentences = []\n",
    "    # using nltk sentence tokenizer\n",
    "    for sentence in sent_tokenize(article_text):\n",
    "        # preprocessing each sentence using our process_sentence function\n",
    "        processed_article_sentences.append(process_sentence(sentence, nlp_object))\n",
    "    # joining preprocessed sentence as a complete paragrams of the article\n",
    "    return \" \".join(processed_article_sentences)\n",
    "\n",
    "articles[\"processed_text\"] = articles[\"text\"].progress_apply(lambda x : process_article(x, nlp))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this\n",
      "True\n",
      "be\n",
      "True\n",
      "do\n",
      "True\n",
      "good\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "nlp_object = spacy.load('en_core_web_sm')\n",
    "doc = nlp_object(\"This is doing good\")\n",
    "for token in doc:\n",
    "    print(token.lemma_)\n",
    "    print(token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>01</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>101</th>\n",
       "      <th>10k</th>\n",
       "      <th>10x</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>120</th>\n",
       "      <th>125</th>\n",
       "      <th>128</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>150</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>1980</th>\n",
       "      <th>1989</th>\n",
       "      <th>1990</th>\n",
       "      <th>1k</th>\n",
       "      <th>1st</th>\n",
       "      <th>20</th>\n",
       "      <th>200</th>\n",
       "      <th>2000</th>\n",
       "      <th>2001</th>\n",
       "      <th>2005</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "      <th>2016</th>\n",
       "      <th>2017</th>\n",
       "      <th>2018</th>\n",
       "      <th>2019</th>\n",
       "      <th>2020</th>\n",
       "      <th>2021</th>\n",
       "      <th>21</th>\n",
       "      <th>...</th>\n",
       "      <th>wise</th>\n",
       "      <th>wish</th>\n",
       "      <th>withdraw</th>\n",
       "      <th>woman</th>\n",
       "      <th>wonder</th>\n",
       "      <th>wonderful</th>\n",
       "      <th>wood</th>\n",
       "      <th>word</th>\n",
       "      <th>work</th>\n",
       "      <th>worker</th>\n",
       "      <th>workflow</th>\n",
       "      <th>working</th>\n",
       "      <th>workout</th>\n",
       "      <th>world</th>\n",
       "      <th>worried</th>\n",
       "      <th>worry</th>\n",
       "      <th>worse</th>\n",
       "      <th>worsen</th>\n",
       "      <th>worth</th>\n",
       "      <th>wow</th>\n",
       "      <th>wrap</th>\n",
       "      <th>write</th>\n",
       "      <th>writer</th>\n",
       "      <th>writing</th>\n",
       "      <th>wrong</th>\n",
       "      <th>www</th>\n",
       "      <th>xgboost</th>\n",
       "      <th>xi</th>\n",
       "      <th>yeah</th>\n",
       "      <th>year</th>\n",
       "      <th>yearly</th>\n",
       "      <th>yell</th>\n",
       "      <th>yellow</th>\n",
       "      <th>yes</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>yo</th>\n",
       "      <th>york</th>\n",
       "      <th>you</th>\n",
       "      <th>young</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zero</th>\n",
       "      <th>zhou</th>\n",
       "      <th>zip</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zuckerberg</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Ensemble methods: bagging, boosting and stacking</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Understanding AUC - ROC Curve</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How to work with object detection datasets in ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11 Dimensionality reduction techniques you sho...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The Time Series Transformer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Type 2 Diabetes Reversal  The Quick Start Guide</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>How a 22 Day Water Fast Changed My Life</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Breaking Your Fast</td>\n",
       "      <td>212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11 Unusual Tips for How to Wake Up Early</td>\n",
       "      <td>213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The 3 Biggest Mistakes Women Make On The Ketog...</td>\n",
       "      <td>214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows  3714 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     00  000  01  05  06  07  10  100  1000  101  10k  10x  11  12  120  125  \\\n",
       "0     0    0   0   0   0   0   0    0     0    0    0    0   0   0    0    0   \n",
       "1     0    0   0   0   0   0   0    0     0    0    0    0   0   0    0    0   \n",
       "2     0    0   0   0   1   0   1    0     0    0    0    0   0   0    0    0   \n",
       "3     0    0   0   0   0   0   0    0     0    0    0    0   1   0    0    0   \n",
       "4     0    0   0   0   0   0   0    0     0    0    0    0   0   0    0    0   \n",
       "..   ..  ...  ..  ..  ..  ..  ..  ...   ...  ...  ...  ...  ..  ..  ...  ...   \n",
       "203   1    0   0   0   0   0   1    0     0    0    0    0   0   1    0    0   \n",
       "204   0    0   0   0   0   0   0    0     0    0    0    0   0   1    0    0   \n",
       "205   0    0   0   0   0   0   1    0     0    0    0    0   1   1    0    0   \n",
       "206   0    0   0   0   0   0   5    0     0    0    0    0   0   0    0    0   \n",
       "207   0    0   0   0   0   0   1    0     0    0    0    0   0   0    0    0   \n",
       "\n",
       "     128  13  14  15  150  16  17  18  19  1980  1989  1990  1k  1st  20  200  \\\n",
       "0      0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
       "1      0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
       "2      0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
       "3      0   0   1   1    0   0   0   0   0     0     0     0   0    0   0    0   \n",
       "4      0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
       "..   ...  ..  ..  ..  ...  ..  ..  ..  ..   ...   ...   ...  ..  ...  ..  ...   \n",
       "203    0   0   0   0    0   0   0   0   0     0     0     0   0    0   1    0   \n",
       "204    0   0   1   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
       "205    0   0   0   0    0   0   0   0   0     0     0     0   0    0   0    0   \n",
       "206    0   0   0   3    0   0   0   2   0     0     0     0   0    0   0    0   \n",
       "207    0   0   0   0    0   0   0   0   0     0     0     0   0    0   1    0   \n",
       "\n",
       "     2000  2001  2005  2008  2009  2010  2011  2012  2013  2014  2015  2016  \\\n",
       "0       0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "1       0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "2       0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "3       0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "4       0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "..    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   \n",
       "203     1     0     0     1     0     0     0     0     0     0     0     0   \n",
       "204     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "205     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "206     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "207     0     0     0     0     0     0     0     0     0     0     0     0   \n",
       "\n",
       "     2017  2018  2019  2020  2021  21  ...  wise  wish  withdraw  woman  \\\n",
       "0       0     0     0     0     0   0  ...     0     0         0      0   \n",
       "1       0     0     0     0     0   0  ...     0     0         0      0   \n",
       "2       0     0     0     0     1   0  ...     0     0         0      0   \n",
       "3       0     0     0     0     0   0  ...     0     0         0      0   \n",
       "4       1     0     1     0     0   0  ...     0     1         0      0   \n",
       "..    ...   ...   ...   ...   ...  ..  ...   ...   ...       ...    ...   \n",
       "203     0     1     0     0     0   0  ...     0     0         0      0   \n",
       "204     0     0     0     0     0   0  ...     0     0         0      0   \n",
       "205     0     0     0     0     0   0  ...     0     0         0      0   \n",
       "206     1     0     0     0     0   0  ...     0     0         0      0   \n",
       "207     0     0     0     0     0   0  ...     0     0         0      5   \n",
       "\n",
       "     wonder  wonderful  wood  word  work  worker  workflow  working  workout  \\\n",
       "0         0          0     0     2     2       0         0        0        0   \n",
       "1         0          0     0     0     0       0         0        0        0   \n",
       "2         0          0     0     0     4       0         0        0        0   \n",
       "3         0          0     0     0     4       0         0        0        0   \n",
       "4         0          0     0     1     2       0         0        0        0   \n",
       "..      ...        ...   ...   ...   ...     ...       ...      ...      ...   \n",
       "203       1          0     0     0     4       0         0        0        0   \n",
       "204       1          0     0     0     4       0         0        0        0   \n",
       "205       0          0     0     0     0       0         0        0        0   \n",
       "206       0          0     0     0    10       0         0        0        0   \n",
       "207       0          0     0     3     2       0         0        0        0   \n",
       "\n",
       "     world  worried  worry  worse  worsen  worth  wow  wrap  write  writer  \\\n",
       "0        0        0      0      0       0      0    0     0      4       0   \n",
       "1        0        0      0      0       0      0    0     0      1       0   \n",
       "2        0        0      0      0       0      0    0     0      2       0   \n",
       "3        3        0      1      0       0      0    0     0      4       0   \n",
       "4        0        0      0      0       0      0    0     0      0       0   \n",
       "..     ...      ...    ...    ...     ...    ...  ...   ...    ...     ...   \n",
       "203      0        0      0      0       1      0    0     0      1       0   \n",
       "204      0        0      0      0       0      0    0     0      0       0   \n",
       "205      0        0      0      0       0      0    0     0      0       0   \n",
       "206      1        0      0      0       0      0    0     0      3       0   \n",
       "207      0        0      1      0       0      0    0     0      2       0   \n",
       "\n",
       "     writing  wrong  www  xgboost  xi  yeah  year  yearly  yell  yellow  yes  \\\n",
       "0          0      0    0        1   0     0     0       0     0       0    0   \n",
       "1          0      0    1        0   0     0     0       0     0       0    0   \n",
       "2          0      1    1        0   0     0     1       0     0       0    0   \n",
       "3          0      0    0        0   0     0     0       0     0       0    1   \n",
       "4          0      0    0        0   0     0     0       0     0       0    0   \n",
       "..       ...    ...  ...      ...  ..   ...   ...     ...   ...     ...  ...   \n",
       "203        0      3    0        0   0     0     4       0     0       0    0   \n",
       "204        0      2    3        0   0     0     1       0     0       0    1   \n",
       "205        0      0    0        0   0     0     0       0     0       0    0   \n",
       "206        0      0    1        0   0     0     2       0     0       0    0   \n",
       "207        0      1    0        0   0     0     1       0     0       0    2   \n",
       "\n",
       "     yesterday  yield  yo  york  you  young  youtube  zero  zhou  zip  zombie  \\\n",
       "0            0      0   0     0    0      0        0     0     0    0       0   \n",
       "1            0      0   0     0    0      0        0     0     0    0       0   \n",
       "2            0      0   0     0    0      0        0     0     0    0       0   \n",
       "3            0      0   0     0    0      0        0     1     0    0       0   \n",
       "4            0      0   0     0    0      0        0     0     0    0       0   \n",
       "..         ...    ...  ..   ...  ...    ...      ...   ...   ...  ...     ...   \n",
       "203          0      0   0     0    0      1        0     0     0    0       0   \n",
       "204          0      0   0     0    1      0        0     0     0    0       0   \n",
       "205          0      0   0     0    0      0        0     1     0    0       0   \n",
       "206          0      0   0     0    0      0        0     0     0    0       1   \n",
       "207          0      0   2     0    0      0        0     0     0    0       0   \n",
       "\n",
       "     zone  zoom  zuckerberg  \\\n",
       "0       0     0           0   \n",
       "1       0     0           0   \n",
       "2       0     0           0   \n",
       "3       0     0           0   \n",
       "4       0     0           0   \n",
       "..    ...   ...         ...   \n",
       "203     0     0           0   \n",
       "204     2     0           0   \n",
       "205     0     0           0   \n",
       "206     1     0           0   \n",
       "207     0     0           0   \n",
       "\n",
       "                                                 TITLE   ID  \n",
       "0     Ensemble methods: bagging, boosting and stacking    1  \n",
       "1                        Understanding AUC - ROC Curve    2  \n",
       "2    How to work with object detection datasets in ...    3  \n",
       "3    11 Dimensionality reduction techniques you sho...    4  \n",
       "4                          The Time Series Transformer    5  \n",
       "..                                                 ...  ...  \n",
       "203    Type 2 Diabetes Reversal  The Quick Start Guide  210  \n",
       "204            How a 22 Day Water Fast Changed My Life  211  \n",
       "205                                 Breaking Your Fast  212  \n",
       "206           11 Unusual Tips for How to Wake Up Early  213  \n",
       "207  The 3 Biggest Mistakes Women Make On The Ketog...  214  \n",
       "\n",
       "[208 rows x 3714 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(min_df=5)\n",
    "# min_df: ignore terms that have a document frequency strictly lower than the given threshold.\n",
    "\n",
    "# Learn the vocabulary dictionary and return document-term matrix\n",
    "bow_features = count_vectorizer.fit_transform(articles[\"processed_text\"]).todense() # todense() returns a matrix\n",
    "# create dataframe\n",
    "bow_features_df = pd.DataFrame(bow_features)\n",
    "bow_features_df.columns = count_vectorizer.get_feature_names_out() # Get output feature names for dataframe columns.\n",
    "bow_features_df[\"TITLE\"] = articles[\"title\"]\n",
    "bow_features_df[\"ID\"] = articles[\"id\"]\n",
    "display(bow_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.19183061351511443, 'Ensemble methods: bagging, boosting and stacking')\n",
      "(0.139743182099794, 'Understanding AUC - ROC Curve')\n",
      "(0.24147810306337553, 'How to work with object detection datasets in COCO format')\n",
      "(0.3231644563297632, '11 Dimensionality reduction techniques you should know in 2021')\n",
      "(0.2391939763550009, 'The Time Series Transformer')\n",
      "(0.14240399288128341, 'Learning a Personalized Homepage')\n",
      "(0.17929542291345354, '6 Data Science Certificates To Level Up Your Career')\n",
      "(0.15112497039746464, 'Transformers Explained Visually (Part 2): How it works, step-by-step')\n",
      "(0.06270092677357267, '60 Python Projects with Source Code')\n",
      "(0.20096989123688136, 'Geometric foundations of Deep Learning')\n",
      "(0.4469151502471941, 'Machine Learning Basics with the K-Nearest Neighbors Algorithm')\n",
      "(0.32165088901715555, 'Building RNN, LSTM, and GRU for time series using PyTorch')\n",
      "(0.1521678591949164, 'Algorithms of the Mind')\n",
      "(0.23028981880582775, '4 Reasons Why Economists Make Great Data Scientists (And Why No One Tells Them)')\n",
      "(0.19666442230490466, 'How To Create A Chatbot with Python & Deep Learning In Less Than An Hour')\n",
      "(0.2273975020895202, 'Machine Learning is Fun Part 5: Language Translation with Deep Learning and the Magic of Sequences')\n",
      "(0.1812125512083253, \"Illustrated Guide to LSTM's and GRU's: A step by step explanation\")\n",
      "(0.15927856472655558, 'How to go from a Python newbie to a Google Certified TensorFlow Developer under two months')\n",
      "(0.4928413304991973, '17 Clustering Algorithms Used In Data Science and Mining')\n",
      "(0.13445288659263072, 'Introduction to Genetic Algorithms  Including Example Code')\n",
      "(0.041751666640918485, 'Photoreal Roman Emperor Project')\n",
      "(0.37672477619870315, 'Fundamental Techniques of Feature Engineering for Machine Learning')\n",
      "(0.17993863840373153, 'How I Got a Job at DeepMind as a Research Engineer (without a Machine Learning Degree!)')\n",
      "(0.1821179193589387, 'Towards the end of deep learning and the beginning of AGI')\n",
      "(0.26454629088051607, 'Tutorial: Document Classification using WEKA')\n",
      "(0.20650540724530414, 'Understanding Random Forest')\n",
      "(0.3730829553821231, 'Probability concepts explained: Maximum likelihood estimation')\n",
      "(0.12981772939413258, 'Transformers Explained Visually (Part 3): Multi-head Attention, deep dive')\n",
      "(0.14020353451794504, '180 Data Science and Machine Learning Projects with Python')\n",
      "(0.19540439251694844, '5 Online Courses I Took as a Self-Taught Data Scientist')\n",
      "(0.19226444766334255, 'Machine Learning is Fun! Part 4: Modern Face Recognition with Deep Learning')\n",
      "(0.7407434076800108, '9 Distance Measures in Data Science')\n",
      "(0.2489742715970487, 'The Sexiest Job of the 21st Century Isn\\'t \"Sexy\" Anymore')\n",
      "(0.20526410116349347, 'Machine Learning is Fun! Part 3: Deep Learning and Convolutional Neural Networks')\n",
      "(0.16443773548426782, 'A Comprehensive Guide to Convolutional Neural Networks  the ELI5 way')\n",
      "(0.1192348856101994, '20 Necessary Requirements of a Perfect Laptop for Data Science and Machine Learning Tasks')\n",
      "(0.2529364572306908, \"3 Beginner Mistakes I've Made in My Data Science Career\")\n",
      "(0.29352245219123996, 'Understanding Variational Autoencoders (VAEs)')\n",
      "(0.13730624407334657, 'Setting Up a New M1 MacBook for Data Science')\n",
      "(0.16285150656512878, \"Are The New M1 Macbooks Any Good for Data Science? Let's Find Out\")\n",
      "(0.23786197799641673, 'Simple and Multiple Linear Regression in Python')\n",
      "(0.19568360891608447, \"I tripled my income with data science. Here's how.\")\n",
      "(0.12706759633133283, 'Keyword Extraction process in Python with Natural Language Processing(NLP)')\n",
      "(0.2486940455383407, 'Machine learning models for 100% better returns in Algo-trading')\n",
      "(0.1235711060613014, 'How to Install Ubuntu Desktop With a Graphical User Interface in WSL2')\n",
      "(0.262814642167761, 'Understanding Contrastive Learning')\n",
      "(0.1907132465754714, 'Understanding Semantic Segmentation with UNET')\n",
      "(0.1776559166744845, 'How Transformers Work')\n",
      "(0.18071376687904064, 'Yes you should understand backprop')\n",
      "(0.29464375221625916, 'PCA using Python (scikit-learn)')\n",
      "(0.24056315905101758, 'Hyperparameter Tuning the Random Forest in Python')\n",
      "(0.13327652790706898, 'Top 3 Reasons Why I Sold My M1 Macbook Pro as a Data Scientist')\n",
      "(0.14912628391216004, 'TRAIN A CUSTOM YOLOv4 OBJECT DETECTOR (Using Google Colab)')\n",
      "(0.11525491878512145, '6 Machine Learning Certificates to Pursue in 2021')\n",
      "(0.297077163264752, 'What to do with \"small\" data?')\n",
      "(0.2497540820326527, 'Time Series Forecasting with PyCaret Regression Module')\n",
      "(0.22630171930069137, '15 Habits I Learned from Highly Effective Data Scientists')\n",
      "(0.3999820573413747, 'OVER 100 Data Scientist Interview Questions and Answers!')\n",
      "(0.16204205483125453, 'Activation Functions in Neural Networks')\n",
      "(0.20183011512341884, 'A One-Stop Shop for Principal Component Analysis')\n",
      "(0.29186517384945876, '5 Things You Should Know About Covariance')\n",
      "(0.1503476094258861, 'How to build your own Neural Network from scratch in Python')\n",
      "(0.11606366406215748, 'The best explanation of Convolutional Neural Networks on the Internet!')\n",
      "(0.18062940015088863, 'Lambda Functions with Practical Examples in Python')\n",
      "(0.24480403158889058, 'The Complete Guide to Time Series Analysis and Forecasting')\n",
      "(0.23565593757091546, '8 Ways to Filter Pandas Dataframes')\n",
      "(0.045260160997789824, 'Standing with Dr. Timnit Gebru  #ISupportTimnit #BelieveBlackWomen')\n",
      "(0.32962149217517295, 'Visualising high-dimensional datasets using PCA and t-SNE in Python')\n",
      "(0.15799026527965565, 'How to Study for the Google Data Analytics Professional Certificate')\n",
      "(0.24630559550544975, 'Is Data Science Still a Rising Career in 2021')\n",
      "(0.17929754886723964, 'Simple Reinforcement Learning with Tensorflow Part 0: Q-Learning with Tables and Neural Networks')\n",
      "(0.22307818310257513, 'How To Grow From Non-Coder to Data Scientist in 6 Months')\n",
      "(0.11624904601057011, \"Apple's New M1 Chip is a Machine Learning Beast\")\n",
      "(0.2937349810054598, 'Train/Test Split and Cross Validation in Python')\n",
      "(0.2816989897241601, 'Text Classification with NLP: Tf-Idf vs Word2Vec vs BERT')\n",
      "(0.3534731090421056, 'The 5 Clustering Algorithms Data Scientists Need to Know')\n",
      "(0.24915539830141836, 'Building A Logistic Regression in Python, Step by Step')\n",
      "(0.03792106958453355, 'Springer has released 65 Machine Learning and Data books for free')\n",
      "(0.1478492998188948, 'Every single Machine Learning course on the internet, ranked by your reviews')\n",
      "(0.14376422116615445, 'TensorFlow Tutorial Part 1')\n",
      "(0.2168292160880105, 'The 7 Best Data Science and Machine Learning Podcasts')\n",
      "(0.31744620419152125, 'Random Forest in Python')\n",
      "(0.23065259178182843, 'How to Land a Data Analytics Job in 6 Months')\n",
      "(0.17804039202102165, 'What is a Transformer?')\n",
      "(0.33798396430172306, 'Fundamentals Of Statistics For Data Scientists and Analysts')\n",
      "(0.22916470671706146, \"Is Google's AI research about to implode?\")\n",
      "(0.2749130401444174, 'Machine Learning is Fun! Part 2')\n",
      "(0.2403417053031966, 'Understanding Generative Adversarial Networks (GANs)')\n",
      "(0.19032499812985096, '17 types of similarity and dissimilarity measures used in data science.')\n",
      "(0.1323081023848233, 'Deep Learning Is Going to Teach Us All the Lesson of Our Lives: Jobs Are for Machines')\n",
      "(0.11065365796389498, 'I interviewed at five top companies in Silicon Valley in five days, and luckily got five job offers')\n",
      "(0.1014483021851014, 'Advantages and Disadvantages of Artificial Intelligence')\n",
      "(0.18746345539771112, 'Could Nim Replace Python?')\n",
      "(0.2988618205807396, 'An End-to-End Project on Time Series Analysis and Forecasting with Python')\n",
      "(0.10728407437597183, 'Data Scientists Will be Extinct in 10 Years')\n",
      "(0.25303224423643844, 'Import all Python libraries in one line of code')\n",
      "(0.19619830525880408, 'Enchanted Random Forest')\n",
      "(0.3468950198983385, 'Machine Learning in a Week')\n",
      "(0.23114308326183386, '50+ Statistics Interview Questions and Answers for Data Scientists for 2022')\n",
      "(0.22210612360073745, 'Top 10 Data Science Projects for Beginners')\n",
      "(0.20620033030957452, 'Check For a Substring in a Pandas DataFrame Column')\n",
      "(0.1622080203096536, 'Machine Learning is Fun Part 6: How to do Speech Recognition with Deep Learning')\n",
      "(0.31700193774699803, 'Everything You Need to Know About Artificial Neural Networks')\n",
      "(0.15972246892971836, 'Ways to Detect and Remove the Outliers')\n",
      "(0.19195366790110666, 'How to Crush the Crypto Market, Quit Your Job, Move to Paradise and Do Whatever You Want the Rest of Your Life')\n",
      "(0.10424777050514557, 'Bitcoin Is Venice')\n",
      "(0.16176125070209277, 'How I Built a Net Worth of $500,000 Before Age 30')\n",
      "(0.044741503889177005, 'Nassim Nicholas Taleb on Self-Education and Doing the Math (Ep. 41  Live at Mercatus)')\n",
      "(0.10463677186125404, 'Public Mint Polkastarter IDO: Launching 23rd of February, Whitelist Now Open!')\n",
      "(0.04417019655216291, 'This is How I Made $40k In Passive Income By Age 26')\n",
      "(0.11934528737033448, 'Introducing The Iron Bank')\n",
      "(0.16608041987485866, 'I used Acorns, Robinhood, and Stash for 2 years. This is what I learned and earned.')\n",
      "(0.11249171087634982, 'Explaining blockchain  how proof of work enables trustless consensus')\n",
      "(0.12951227270723478, 'Wealthfront:Silicon Valley Tech at Wall Street Prices')\n",
      "(0.13506699622519514, 'Crypto Trading Bots  A helpful guide for beginners [2020]')\n",
      "(0.14035849200348824, \"Why People Still Don't Get Cryptocurrency\")\n",
      "(0.09159901695550901, \"Australia's Economy is a House of Cards\")\n",
      "(0.10821575414165444, 'My First Two Months Trading Stocks with Robinhood')\n",
      "(0.07652353198966047, 'What It Takes to Go from $0 to $1 Million in Less Than One Year')\n",
      "(0.13814280402911028, 'Tesla Is Dead (And Elon Musk Knows It)')\n",
      "(0.09856567603798895, \"Uber's Credit Card Is Bankrupting Restaurants... and It's All Your Fault\")\n",
      "(0.13652835618095985, 'A Quick Starter Guide to Leveraged Trading at BitMEX')\n",
      "(0.13022779425385247, 'I Made $3 Million in Crypto. These are the 26 Rules I Learned.')\n",
      "(0.11782486482163407, 'The Black-Scholes formula, explained')\n",
      "(0.08829914145925404, 'You Will Never Be Rich If You Keep Doing These 10 things')\n",
      "(0.117808855864931, 'Heroes Give, Superheroes Borrow')\n",
      "(0.1314454002418737, \"Could Bitcoin's Bull Market End Next Month?\")\n",
      "(0.17409111489474127, 'The Exact Steps I Followed to Make $1,500+ of Passive Income Every Month')\n",
      "(0.1364733532693546, \"You May Have A Poor Person's Mindset And Not Know It\")\n",
      "(0.10256987855742988, 'A Definitive Guide to Why Life Is So Terrible for Most Millennials')\n",
      "(0.1826428399091764, 'The Berkshire Hathaway of The Internet')\n",
      "(0.21380829352832814, 'How to invest in Bitcoin properly. Blockchain and other cryptocurrencies')\n",
      "(0.0599735554536433, 'Machine learning in finance: Why, what & how')\n",
      "(0.006462537010946699, 'Minimum Wage Artists')\n",
      "(0.08642042766332719, 'Richart + @GoGo ')\n",
      "(0.1348661646138916, 'How to store Bitcoins and other cryptocurrencies properly.')\n",
      "(0.24384664521464425, 'I was wrong about Ethereum')\n",
      "(0.10468595144014649, 'Deep Learning the Stock Market')\n",
      "(0.20411325477760278, \"Financial Fridays: It's Financial Suicide To Own A House\")\n",
      "(0.12551322456014627, 'Gauge Theory Does Not Fix This')\n",
      "(0.14719424593340494, 'High Frequency Trading on the Coinbase Exchange')\n",
      "(0.125955801530439, \"A $1000 Bitcoin Investment Won't Make You Rich\")\n",
      "(0.13295198644101802, 'How To Legally Own Another Person')\n",
      "(0.10196116748228208, '5 Things NOT to Do in the Robinhood App for Stock Trading')\n",
      "(0.0810942155934362, 'The One Word That Explains Why Economics Professors Are Not Billionaires')\n",
      "(0.10216786477896643, 'Building your credit history')\n",
      "(0.10673076918976121, 'I Retired at 35  Here Are 5 Lessons from My First 6 Months of Freedom')\n",
      "(0.07862916213639998, 'Why you should never use Upwork, ever.')\n",
      "(0.16056456361330437, \"Facebook Can't Be Fixed.\")\n",
      "(0.3034807764290822, 'A comprehensive guide to downloading stock prices in Python')\n",
      "(0.008594787467824886, 'Detecting Credit Card Fraud Using Machine Learning')\n",
      "(0.16490990110945108, '2018  & : KOKO COMBO icash ')\n",
      "(0.10526895304129441, 'Is Wealthfront Worth it?')\n",
      "(0.13584511012091074, 'How I Slowly Became A \"Middle-Class\" Millionaire')\n",
      "(0.13567417875210214, 'SPY vs. QQQ: Investing in Different Indexes')\n",
      "(0.07484589876065367, 'I Won $104 Million for Blowing the Whistle on My CompanyBut Somehow I Was the Only One Who Went to Jail')\n",
      "(0.12172738463434547, 'Robinhood Lends \"Your\" Shares to Short Sellers (and Keeps All the Proceeds)')\n",
      "(0.11533924337333858, 'The Secret to Making 2000% in Stocks Overnight, the Anavex story.')\n",
      "(0.12012713000330427, '4 Unusual Side Hustles I Do to Earn an Extra $1,500 a Month')\n",
      "(0.10700088938379962, \"Meet 'Spoofy'. How a Single entity dominates the price of Bitcoin.\")\n",
      "(0.14074162625684944, 'How I Started Saving a TON of Money.')\n",
      "(0.20133675366609458, 'How I transformed $6,000 to $3,000,000')\n",
      "(0.04820563923277886, 'Cliff Asness on Marvel vs. DC and Why Never to Share a Gym with Cirque du Soleil (Ep. 5  Live at Mason)')\n",
      "(0.09502567695341356, 'Paypal froze our funds, then offered us a business loan')\n",
      "(0.17545635983605956, 'A Visual Explanation of Algorithmic Stablecoins')\n",
      "(0.05029217881656463, 'Algorithmic Trading Bot: Python')\n",
      "(0.039247298566508625, \"Chernobyl's Blown Up Reactor 4 Just Woke Up\")\n",
      "(0.0974669097070863, 'The Unexpected Case of the Disappearing Flu')\n",
      "(0.10389710375485536, 'The Diet & Workout Plan of a Full-Time Traveling Family  HIS')\n",
      "(0.04956539626526453, 'The Cult of Work You Never Meant to Join')\n",
      "(0.06752486456855891, '5 Things to do in the First 24 Hours of a Cold or Flu')\n",
      "(0.11406194985678936, 'The Sweet Spot for Intermittent Fasting')\n",
      "(0.20694780802258356, 'The 6 Types of ICU Nurse')\n",
      "(0.08970638611604934, 'How to biohack your intelligence  with everything from sex to modafinil to MDMA')\n",
      "(0.2012898761814993, '8 Common Arguments Against Vaccines')\n",
      "(0.12244120551211454, 'A Reasonably Detailed Guide to Optimizing Your iPhone for Productivity, Focus and Your Own Health')\n",
      "(0.05806383902474188, 'The cure for type 2 diabetes is known, but few are aware')\n",
      "(0.1836219038136356, 'Face mapping: how to deal with acne like a true detective')\n",
      "(0.11550885138353512, \"I'm 32 and spent $200k on biohacking. Became calmer, thinner, extroverted, healthier & happier.\")\n",
      "(0.07001808963862469, 'I need more iron')\n",
      "(0.08201189073851689, 'What I Learned From Quitting Coffee After 15 Years Of Daily Consumption')\n",
      "(0.11236163463343604, 'The forgotten art of untucking the tail')\n",
      "(0.17218838395713082, \"Hip Replacement Isn't What It Used To Be 12 Weeks Ago\")\n",
      "(0.1291637960068166, 'Coronavirus: Why You Must Act Now')\n",
      "(0.07415289196999283, 'Manufacturers have been using nanotechnology-derived graphene in face masks  now there are safety concerns')\n",
      "(0.1051383624384967, 'Eben Byers: The Man Who Drank Radioactive Water Until His Jaw Fell Off')\n",
      "(0.10175525430080853, 'My Intermittent Fasting Lifestyle: How I Dropped 50 Pounds')\n",
      "(0.08206898611017, \"I Stopped Drinking for 30 Days. Here's What Happened.\")\n",
      "(0.13960014392931155, 'How to lose 10+ pounds of fat a month- even if you have a slow metabolism')\n",
      "(0.046849568262565575, \"If You're Buying Your Weed Solely Based on the THC Level, You're Doing it Wrong.\")\n",
      "(0.06247066310647312, '2016 Is Not Killing People')\n",
      "(0.12283345805614918, 'How I Learned to Sleep Only Three Hours Per Night (and Why You Should Too)')\n",
      "(0.21830988723660646, 'I fasted for 11 days, here is what happened.')\n",
      "(0.05434365631441656, 'Coronavirus: The Hammer and the Dance')\n",
      "(0.11714095029449376, 'What Happens in Your Body When You Quit Drinking')\n",
      "(0.15187938262269654, 'The Science Behind Fat Metabolism')\n",
      "(0.12292406381639126, 'The Easiest Way to Lose 125 Pounds Is to Gain 175 Pounds')\n",
      "(0.12998049906515782, '7 things I did to reboot my life.')\n",
      "(0.07475174619086875, 'How I lost 10kg in 60 days: My 7-step weight loss plan')\n",
      "(0.0772707049892022, \"The Foo Fighters' AIDS denialism should be on the record\")\n",
      "(0.09708328407640748, 'The Uncut History of Male Circumcision')\n",
      "(0.17359566340701604, '10 Things You Can Do This Morning To Heal Your Anxiety')\n",
      "(0.06537033415596237, \"I just lost 100 pounds. Here's whyalmost nobody else will!\")\n",
      "(0.13371532081915913, 'Type 2 Diabetes Reversal  The Quick Start Guide')\n",
      "(0.06688601729381308, 'How a 22 Day Water Fast Changed My Life')\n",
      "(0.10002748610937628, 'Breaking Your Fast')\n",
      "(0.1310305286247644, '11 Unusual Tips for How to Wake Up Early')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "this_article_rep = bow_features_df[bow_features_df[\"ID\"] == 90][count_vectorizer.get_feature_names_out()]\n",
    "other_article_rep = bow_features_df[bow_features_df[\"ID\"] != 90][count_vectorizer.get_feature_names_out()]\n",
    "# # calculating cosine similarity\n",
    "# similarity_matrix = cosine_similarity(this_article_rep, other_article_rep)\n",
    "# similar_articles = list(zip(similarity_matrix[0].tolist(), bow_features_df[\"TITLE\"].tolist()))\n",
    "# # sorting\n",
    "# similar_articles = sorted(similar_articles, key = lambda x : x[0], reverse = True)\n",
    "# print(\"Reference Article : {}\".format(bow_features_df[bow_features_df[\"ID\"] == 90][\"TITLE\"].values[0]))\n",
    "\n",
    "# print(\"**** Similar Articles ****\")\n",
    "# # top 5 similar articles\n",
    "# for score, title in similar_articles[:5]:\n",
    "#     print(title)\n",
    "\n",
    "for i in zip(list(cosine_similarity(this_article_rep, other_article_rep)[0]),bow_features_df['TITLE'].to_list()):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Ensemble methods: bagging, boosting and stacking\n",
       "1                          Understanding AUC - ROC Curve\n",
       "2      How to work with object detection datasets in ...\n",
       "3      11 Dimensionality reduction techniques you sho...\n",
       "4                            The Time Series Transformer\n",
       "                             ...                        \n",
       "203      Type 2 Diabetes Reversal  The Quick Start Guide\n",
       "204              How a 22 Day Water Fast Changed My Life\n",
       "205                                   Breaking Your Fast\n",
       "206             11 Unusual Tips for How to Wake Up Early\n",
       "207    The 3 Biggest Mistakes Women Make On The Ketog...\n",
       "Name: TITLE, Length: 208, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_features_df['TITLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "207"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cosine_similarity(this_article_rep, other_article_rep)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
