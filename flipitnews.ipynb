{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Statement:\n",
    "\n",
    "**Context**:\n",
    "The Gurugram-based FlipItNews aims to revolutionize the way Indians perceive finance, business, and capital market investment, by giving it a boost through artificial intelligence (AI) and machine learning (ML). They’re on a mission to reinvent financial literacy for Indians, where financial awareness is driven by smart information discovery and engagement with peers. Through their smart content discovery and contextual engagement, the company is simplifying business, finance, and investment for millennials and first-time investors\n",
    "\n",
    "**Objective**:\n",
    "The goal of this project is to use a bunch of news articles extracted from the companies’ internal database and categorize them into several categories like politics, technology, sports, business and entertainment based on their content. Use natural language processing and create & compare at least three different models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attribute Information:\n",
    "\n",
    "* Article\n",
    "* Category\n",
    "\n",
    "The feature names are themselves pretty self-explanatory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Approach:\n",
    "\n",
    "1. Importing the libraries\n",
    "2. Loading the dataset\n",
    "  * Mounting the drive\n",
    "  * Reading the data file\n",
    "3. Data Exploration\n",
    "  * Shape of the dataset\n",
    "  * News articles per category\n",
    "4. Text Processing\n",
    "  * Removing the non-letters\n",
    "  * Tokenizing the text\n",
    "  * Removing stopwords\n",
    "  * Lemmatization\n",
    "5. Data Transformation\n",
    "  * Converting to lower case\n",
    "  * Encoding the target variable\n",
    "  * Bag of Words\n",
    "  * TF-IDF\n",
    "  * Train-Test Split\n",
    "6. Model Training & Evaluation\n",
    "  * Simple Approach\n",
    "    * Naive Bayes\n",
    "  * Functionalized Code\n",
    "    * Decision Tree\n",
    "    * Nearest Neighbors\n",
    "    * Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the libraries -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (3.10.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/leenasingh/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.14.0 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.24.4)\n",
      "Requirement already satisfied: pandas>=1.0.5 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.5.3)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from category_encoders) (0.5.3)\n",
      "Requirement already satisfied: scikit-learn>=1.6.0 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.6.1)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from category_encoders) (1.10.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from category_encoders) (0.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from pandas>=1.0.5->category_encoders) (2023.3.post1)\n",
      "Requirement already satisfied: six in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.6.0->category_encoders) (3.5.0)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/leenasingh/anaconda3/lib/python3.11/site-packages (from statsmodels>=0.9.0->category_encoders) (23.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# To ignore all warnings\n",
    "import warnings\n",
    "\n",
    "# For reading & manipulating the data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# For visualizing the data\n",
    "!pip install matplotlib --upgrade\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# To use Regular Expressions\n",
    "import re\n",
    "\n",
    "# To use Natural Language Processing\n",
    "import nltk\n",
    "\n",
    "# For tokenization\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "# To remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# For lemmetization\n",
    "from nltk import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# For BoW & TF-IDF\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# For encoding the categorical variable\n",
    "!pip install category_encoders\n",
    "import category_encoders as ce\n",
    "\n",
    "# To try out different ML models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# To perform train-test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Performace Metrics for evaluating the model\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>Technology</td>\n",
       "      <td>mobile gaming takes off in india gaming on the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1875</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>oscars race enters final furlong the race for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>Technology</td>\n",
       "      <td>the gaming world in 2005 if you have finished ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Business</td>\n",
       "      <td>german growth goes into reverse germany s econ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>Technology</td>\n",
       "      <td>evil twin  fear for wireless net people using ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1123</th>\n",
       "      <td>Business</td>\n",
       "      <td>qantas sees profits fly to record australian a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>Entertainment</td>\n",
       "      <td>new york rockers top talent poll new york elec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>Technology</td>\n",
       "      <td>ea to take on film and tv giants video game gi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Sports</td>\n",
       "      <td>clijsters could play aussie open kim clijsters...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1641</th>\n",
       "      <td>Sports</td>\n",
       "      <td>tulu to appear at caledonian run two-time olym...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Category                                            Article\n",
       "819      Technology  mobile gaming takes off in india gaming on the...\n",
       "1875  Entertainment  oscars race enters final furlong the race for ...\n",
       "1982     Technology  the gaming world in 2005 if you have finished ...\n",
       "39         Business  german growth goes into reverse germany s econ...\n",
       "1364     Technology  evil twin  fear for wireless net people using ...\n",
       "1123       Business  qantas sees profits fly to record australian a...\n",
       "1528  Entertainment  new york rockers top talent poll new york elec...\n",
       "1314     Technology  ea to take on film and tv giants video game gi...\n",
       "345          Sports  clijsters could play aussie open kim clijsters...\n",
       "1641         Sports  tulu to appear at caledonian run two-time olym..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('flipitnews-data.csv')\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's check the shape of the dataset that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows and columns: (2225, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"No. of rows and columns: {}\".format(df.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation: There are 2,225 different news articles present in the dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Category', ylabel='count'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Distirbution of Category\n",
    "sns.countplot(x=df['Category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation: Most of the news articles in the dataset are from Business & Sports category.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before processing -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worldcom boss  left books alone  former worldcom boss bernie ebbers  who is accused of overseeing an $11bn (£5.8bn) fraud  never made accounting decisions  a witness has told jurors.  david myers made the comments under questioning by defence lawyers who have been arguing that mr ebbers was not responsible for worldcom s problems. the phone company collapsed in 2002 and prosecutors claim that losses were hidden to protect the firm s shares. mr myers has already pleaded guilty to fraud and is assisting prosecutors.  on monday  defence lawyer reid weingarten tried to distance his client from the allegations. during cross examination  he asked mr myers if he ever knew mr ebbers  make an accounting decision  .  not that i am aware of   mr myers replied.  did you ever know mr ebbers to make an accounting entry into worldcom books   mr weingarten pressed.  no   replied the witness. mr myers has admitted that he ordered false accounting entries at the request of former worldcom chief financial officer scott sullivan. defence lawyers have been trying to paint mr sullivan  who has admitted fraud and will testify later in the trial  as the mastermind behind worldcom s accounting house of cards.  mr ebbers  team  meanwhile  are looking to portray him as an affable boss  who by his own admission is more pe graduate than economist. whatever his abilities  mr ebbers transformed worldcom from a relative unknown into a $160bn telecoms giant and investor darling of the late 1990s. worldcom s problems mounted  however  as competition increased and the telecoms boom petered out. when the firm finally collapsed  shareholders lost about $180bn and 20 000 workers lost their jobs. mr ebbers  trial is expected to last two months and if found guilty the former ceo faces a substantial jail sentence. he has firmly declared his innocence.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Article'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming vs. Lemmatization in NLP**\n",
    "\n",
    "Both stemming and lemmatization are techniques used in Natural Language Processing (NLP) to reduce words to their root or base form. \n",
    "\n",
    "This helps in text preprocessing, improving the efficiency of machine learning models by reducing vocabulary size.\n",
    "\n",
    "1. Stemming\n",
    "\n",
    "Definition:\n",
    "    \n",
    "Stemming is a rule-based process of removing suffixes from a word to obtain its root form, often without considering the actual meaning. \n",
    "It may result in words that aren’t real dictionary words.\n",
    "\n",
    "(e.g., “studies” → “studi”).\n",
    "\n",
    "2. Lemmatization\n",
    "\n",
    "Definition:\n",
    "    \n",
    "Lemmatization reduces words to their base or dictionary form (lemma) using linguistic rules and considers the context and meaning of the word. \n",
    "Unlike stemming, lemmatization always results in valid words.\n",
    "\n",
    "(e.g., “studies” → “study”).\n",
    "\n",
    "When to Use What?\n",
    "\n",
    "•\tUse Stemming when speed is more important than accuracy (e.g., search engines).\n",
    "\n",
    "•\tUse Lemmatization when meaning and correctness matter (e.g., chatbots, text summarization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words(\"english\"))\n",
    "\n",
    "def text_process(sent):\n",
    "    \n",
    "    #Converting to lowercase\n",
    "    sent= sent.lower()\n",
    "    \n",
    "    # Removing non-letters\n",
    "    sent = re.sub('[^a-zA-Z]', ' ', sent)\n",
    "\n",
    "    # Word tokenizing the text\n",
    "    words = nltk.word_tokenize(sent)\n",
    "\n",
    "    # Removing stopwords\n",
    "    filtered_sent = [w for w in words if not w in stop_words]\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    new_txt = [lemmatizer.lemmatize(word) for word in filtered_sent]\n",
    "    new_txt = \" \".join(new_txt)\n",
    "\n",
    "    return new_txt\n",
    "\n",
    "df['Article'] = df['Article'].apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After processing -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'worldcom bos left book alone former worldcom bos bernie ebbers accused overseeing bn bn fraud never made accounting decision witness told juror david myers made comment questioning defence lawyer arguing mr ebbers responsible worldcom problem phone company collapsed prosecutor claim loss hidden protect firm share mr myers already pleaded guilty fraud assisting prosecutor monday defence lawyer reid weingarten tried distance client allegation cross examination asked mr myers ever knew mr ebbers make accounting decision aware mr myers replied ever know mr ebbers make accounting entry worldcom book mr weingarten pressed replied witness mr myers admitted ordered false accounting entry request former worldcom chief financial officer scott sullivan defence lawyer trying paint mr sullivan admitted fraud testify later trial mastermind behind worldcom accounting house card mr ebbers team meanwhile looking portray affable bos admission pe graduate economist whatever ability mr ebbers transformed worldcom relative unknown bn telecom giant investor darling late worldcom problem mounted however competition increased telecom boom petered firm finally collapsed shareholder lost bn worker lost job mr ebbers trial expected last two month found guilty former ceo face substantial jail sentence firmly declared innocence'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Article'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encoding the target variable -**\n",
    "\n",
    "We will be using the OrdinalEncoder from category_encoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Ordinal Encoding?\n",
    "\n",
    "Ordinal encoding is a technique used to convert categorical variables into numeric values while preserving the natural order of categories. It is useful for ordinal data where categories have a meaningful ranking (e.g., “Low”, “Medium”, “High”).\n",
    "\n",
    "Unlike Label Encoding (which assigns arbitrary numbers), Ordinal Encoding allows you to specify the category order to maintain proper relationships in machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode = ce.OrdinalEncoder(cols=['Category'])\n",
    "df = encode.fit_transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outcome labels after encoding -**\n",
    "\n",
    "Category:\n",
    "\n",
    "1 - Technology\n",
    "\n",
    "2 - Business\n",
    "\n",
    "3 - Sports\n",
    "\n",
    "4 - Entertainment\n",
    "\n",
    "5 - Politics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of Words / TF-IDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've given the user a choice to select one of the following techniques for vectorizing the data -\n",
    "* BoW\n",
    "* TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both Bag of Words (BoW) and TF-IDF are text vectorization techniques used in Natural Language Processing (NLP) to convert text into numerical representations for machine learning models.\n",
    "\n",
    "**1. Bag of Words (BoW)**\n",
    "\n",
    "Definition\n",
    "\n",
    "The Bag of Words (BoW) model represents text as a collection of words without considering order or context. It creates a matrix where:\n",
    "\n",
    "•\tEach row represents a document (sentence, paragraph, or text).\n",
    "\n",
    "•\tEach column represents a unique word (feature) from the entire corpus.\n",
    "\n",
    "•\tThe values represent the frequency of words in the document.\n",
    "\n",
    "\n",
    "**2. Term Frequency-Inverse Document Frequency (TF-IDF)**\n",
    "\n",
    "Definition\n",
    "\n",
    "TF-IDF (Term Frequency - Inverse Document Frequency) is a more advanced text representation technique that:\n",
    "\n",
    "•\tPenalizes frequently occurring words (like “the”, “is”, etc.)\n",
    "\n",
    "•\tGives higher importance to rare but significant words\n",
    "\n",
    "It consists of two components:\n",
    "\n",
    "1.\tTerm Frequency (TF): Measures how often a word appears in a document.\n",
    "\n",
    "TF = Number of times word appears in a document/Total words in the document\n",
    "\n",
    "2.\tInverse Document Frequency (IDF): Measures how unique a word is across documents.\n",
    "\n",
    "IDF = log({Total number of documents}/{Number of documents containing the word})\n",
    "\n",
    "\n",
    "Final TF-IDF score:\n",
    "\n",
    "TF-IDF = TF * IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion\n",
    "\n",
    "•\tUse BoW when you need a quick, simple representation of text data.\n",
    "\n",
    "•\tUse TF-IDF when you need to focus on important words while ignoring common ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going ahead with BoW\n"
     ]
    }
   ],
   "source": [
    "choice = int(input(\"Choose \\n (1) If you want to use Bag of Words \\n (2) If you want to use TF-IDF \\n Choice: \"))\n",
    "\n",
    "if choice == 1:\n",
    "    print('Going ahead with BoW')\n",
    "    cv = CountVectorizer(max_features=5000) #BOW\n",
    "    X = cv.fit_transform(df. Article).toarray()\n",
    "    y = np.array(df['Category'].values)\n",
    "\n",
    "elif choice == 2:\n",
    "    print('Going ahead with TF-IDF')\n",
    "    tf_idf = TfidfVectorizer() #TF-IDF\n",
    "    X = tf_idf.fit_transform(df.Article).toarray()\n",
    "    y = np.array(df['Category'].values)\n",
    "\n",
    "else:\n",
    "    print(\"Wrong Input!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25,\n",
    "                                                shuffle=True, stratify=y,\n",
    "                                                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of rows in train set is 1668.\n",
      "No. of rows in test set is 557.\n"
     ]
    }
   ],
   "source": [
    "#shape of the train and test data\n",
    "\n",
    "print(\"No. of rows in train set is {}.\".format(X_train.shape[0]))\n",
    "print(\"No. of rows in test set is {}.\".format(X_val.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naïve Bayes is a probabilistic classification algorithm based on Bayes’ Theorem. It assumes that features are independent of each other, which is why it’s called “naïve.” Despite this assumption, it performs well in many real-world applications, especially in text classification (spam detection, sentiment analysis, etc.).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understanding Bayes’ Theorem**\n",
    "\n",
    "Naïve Bayes is based on Bayes’ Theorem, which calculates the probability of a hypothesis (class label) given some evidence (features):\n",
    "\n",
    "\n",
    "P(A|B) = {P(B|A).P(A)}/{P(B)}\n",
    "\n",
    "\n",
    "Where:\n",
    "•\t P(A|B)  = Posterior Probability (Probability of class A given data B)\n",
    "\n",
    "•\t P(B|A)  = Likelihood (Probability of data B occurring in class A)\n",
    "\n",
    "•\t P(A)  = Prior Probability (Probability of class A occurring)\n",
    "\n",
    "•\t P(B)  = Evidence (Overall probability of data B)\n",
    "\n",
    "\n",
    "2. How Naïve Bayes Works in Classification\n",
    "\n",
    "\t1.\tCalculate the prior probability for each class.\n",
    "\n",
    "\t2.\tCompute the likelihood (conditional probability of each feature given the class).\n",
    "\n",
    "\t3.\tUse Bayes’ Theorem to calculate the posterior probability for each class.\n",
    "    \n",
    "\t4.\tAssign the class with the highest probability as the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multinomial Naïve Bayes (For Text Data)**\n",
    "\n",
    "•\tUsed for text classification (spam detection, sentiment analysis, etc.)\n",
    "\n",
    "•\tWorks well with Bag of Words (BoW) or TF-IDF representations.\n",
    "\n",
    "•\tUses word frequencies as features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model -\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy :0.989\n",
      "Test accuracy :0.978\n"
     ]
    }
   ],
   "source": [
    "# Calculating the train & test accuracy -\n",
    "nb_train = accuracy_score(y_train, nb.predict(X_train))\n",
    "nb_test = accuracy_score(y_val, nb.predict(X_val))\n",
    "\n",
    "print(\"Train accuracy :{:.3f}\".format(nb_train))\n",
    "print(\"Test accuracy :{:.3f}\".format(nb_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions on the test set -\n",
    "y_pred_nb = nb.predict(X_val)\n",
    "y_pred_proba_nb = nb.predict_proba(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 2, 2, 2, 1, 4, 2, 3, 1, 2, 5, 5, 5, 1, 4, 3, 4, 3, 5, 5, 2,\n",
       "       2, 3, 4, 2, 3, 3, 3, 2, 2, 3, 2, 3, 5, 4, 3, 3, 3, 4, 2, 3, 2, 5,\n",
       "       1, 2, 5, 1, 1, 2, 5, 3, 5, 2, 5, 3, 5, 3, 5, 1, 3, 1, 1, 3, 1, 5,\n",
       "       2, 1, 2, 4, 3, 5, 5, 4, 5, 3, 2, 5, 1, 3, 4, 3, 4, 2, 4, 3, 4, 4,\n",
       "       3, 5, 2, 1, 1, 3, 3, 3, 2, 4, 4, 2, 5, 1, 5, 1, 4, 4, 2, 3, 1, 4,\n",
       "       4, 3, 1, 3, 1, 2, 3, 5, 4, 1, 3, 2, 4, 4, 5, 4, 3, 5, 3, 4, 3, 4,\n",
       "       3, 3, 5, 4, 5, 5, 5, 5, 3, 3, 5, 1, 3, 1, 4, 2, 2, 3, 4, 4, 3, 2,\n",
       "       4, 5, 2, 5, 3, 3, 4, 5, 2, 5, 3, 5, 1, 4, 4, 2, 1, 2, 1, 2, 1, 3,\n",
       "       2, 3, 3, 3, 3, 2, 3, 4, 4, 1, 2, 4, 3, 5, 4, 3, 2, 5, 2, 3, 3, 1,\n",
       "       3, 1, 5, 2, 1, 2, 2, 2, 2, 4, 4, 2, 5, 3, 5, 1, 1, 5, 2, 2, 3, 2,\n",
       "       2, 5, 5, 3, 5, 5, 5, 1, 4, 4, 4, 3, 3, 3, 1, 2, 1, 2, 2, 5, 3, 5,\n",
       "       2, 4, 5, 2, 3, 3, 5, 3, 5, 3, 4, 1, 1, 1, 3, 2, 4, 1, 1, 1, 2, 1,\n",
       "       5, 1, 5, 2, 2, 4, 1, 3, 5, 4, 1, 4, 1, 2, 1, 2, 5, 3, 1, 2, 4, 3,\n",
       "       1, 4, 5, 4, 2, 5, 4, 5, 3, 3, 1, 1, 2, 5, 1, 4, 1, 2, 2, 4, 2, 5,\n",
       "       1, 1, 4, 5, 3, 3, 1, 5, 1, 4, 3, 3, 5, 2, 2, 1, 2, 1, 4, 2, 2, 1,\n",
       "       1, 3, 1, 2, 2, 3, 4, 2, 2, 2, 2, 1, 4, 5, 2, 5, 5, 1, 4, 5, 2, 1,\n",
       "       2, 3, 1, 3, 5, 5, 3, 2, 1, 1, 5, 2, 1, 2, 5, 4, 1, 4, 2, 1, 3, 3,\n",
       "       5, 4, 3, 1, 3, 4, 3, 2, 1, 2, 3, 1, 5, 2, 2, 4, 4, 3, 1, 5, 3, 3,\n",
       "       2, 3, 4, 3, 3, 1, 5, 4, 5, 3, 5, 3, 5, 1, 5, 1, 2, 5, 4, 3, 3, 4,\n",
       "       2, 4, 5, 3, 5, 2, 4, 1, 2, 2, 2, 4, 5, 4, 5, 5, 5, 3, 4, 1, 5, 3,\n",
       "       2, 4, 2, 1, 5, 5, 3, 2, 1, 1, 4, 4, 3, 1, 2, 2, 4, 3, 2, 3, 2, 1,\n",
       "       2, 4, 3, 5, 3, 4, 2, 4, 4, 2, 1, 2, 3, 3, 3, 5, 5, 4, 5, 1, 3, 2,\n",
       "       4, 3, 1, 5, 2, 5, 5, 2, 5, 5, 1, 2, 3, 1, 4, 2, 1, 2, 1, 2, 4, 5,\n",
       "       3, 3, 3, 5, 1, 2, 2, 5, 5, 4, 3, 1, 2, 4, 3, 4, 5, 3, 2, 2, 3, 2,\n",
       "       5, 1, 4, 2, 1, 1, 1, 2, 1, 4, 5, 3, 5, 1, 4, 2, 5, 3, 4, 3, 3, 3,\n",
       "       2, 3, 4, 1, 3, 1, 3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+000, 8.61680255e-105, 3.28402811e-147,\n",
       "        7.51041725e-094, 9.06420082e-137],\n",
       "       [1.00000000e+000, 1.42319371e-074, 2.34081707e-149,\n",
       "        9.50899723e-089, 1.61523687e-114],\n",
       "       [5.43631304e-057, 1.00000000e+000, 1.34889284e-082,\n",
       "        1.25406540e-058, 7.81799175e-053],\n",
       "       ...,\n",
       "       [7.82762321e-046, 4.69674513e-049, 1.00000000e+000,\n",
       "        1.28013772e-038, 4.14485259e-044],\n",
       "       [1.00000000e+000, 1.35511605e-156, 1.03775881e-248,\n",
       "        1.53729775e-177, 4.94179436e-181],\n",
       "       [1.36348745e-101, 2.43561904e-086, 1.00000000e+000,\n",
       "        2.56360202e-091, 1.42763671e-088]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba_nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1️⃣ What is ROC AUC Score?\n",
    "\n",
    "ROC AUC Score is a performance metric for classification models, especially binary classification. It evaluates how well the model distinguishes between positive and negative classes.\n",
    "\n",
    "📌 Key Terms:<br>\n",
    "•\tROC (Receiver Operating Characteristic) Curve: A graph that shows the trade-off between True Positive Rate (TPR) and False Positive Rate (FPR) at different classification thresholds.<br>\n",
    "•\tAUC (Area Under the Curve): A single value that summarizes the performance of the ROC curve.\n",
    "\n",
    "\n",
    "Formula for TPR (Recall) and FPR:\n",
    "\n",
    "TPR = {TP}/{TP + FN} \n",
    "\n",
    "\n",
    "FPR = {FP}/{FP + TN} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "🔹 Higher AUC (i.e. approaching 1) = Better model at distinguishing classes.<br>\n",
    "🔹 If AUC ≈ 0.5, the model is as good as random guessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3️⃣ When to Use ROC AUC?\n",
    "\n",
    "✅ For Imbalanced Datasets:<br>\n",
    "•\tAccuracy can be misleading when one class is dominant.<br>\n",
    "•\tROC AUC is threshold-independent, making it useful for imbalanced classes.<br>\n",
    "\n",
    "✅ For Binary Classification:<br>\n",
    "•\tWorks best when predicting two classes (e.g., spam vs. not spam, fraud vs. non-fraud).\n",
    "\n",
    "✅ For Comparing Models:<br>\n",
    "•\tIf two models have similar accuracy, compare their ROC AUC scores to see which is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC Score: 0.998\n"
     ]
    }
   ],
   "source": [
    "# Computing the ROC AUC score -\n",
    "print(\"ROC AUC Score: {:.3f}\".format(roc_auc_score(y_val, y_pred_proba_nb, multi_class='ovr')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is One-vs-Rest (OvR)?\n",
    "\n",
    "One-vs-Rest (also called One-vs-All, OvA) is a multi-class classification strategy that transforms a multi-class problem into multiple binary classification problems.\n",
    "\n",
    "For a classification task with N classes, OvR:<br>\n",
    "•\tTrains N binary classifiers, one for each class.<br>\n",
    "•\tEach classifier distinguishes one class (positive) from all other classes (negative).<br>\n",
    "•\tThe class with the highest probability is chosen as the final prediction.\n",
    "\n",
    "How it Works?\n",
    "\n",
    "For a dataset with 3 classes:<br>\n",
    "🚀 Classes: Apple, Banana, Cherry\n",
    "\n",
    "✅ OvR creates 3 separate classifiers:<br>\n",
    "1️⃣ Classifier 1: Apple vs. (Banana, Cherry)<br>\n",
    "2️⃣ Classifier 2: Banana vs. (Apple, Cherry)<br>\n",
    "3️⃣ Classifier 3: Cherry vs. (Apple, Banana)\n",
    "\n",
    "During prediction, the class with the highest confidence score is selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.979\n",
      "Recall: 0.978\n",
      "F1 Score: 0.978\n"
     ]
    }
   ],
   "source": [
    "# Computing the precision, recall & f1 score -\n",
    "precision = precision_score(y_val, y_pred_nb, average='weighted')\n",
    "recall = recall_score(y_val, y_pred_nb, average='weighted')\n",
    "f1 = f1_score(y_val, y_pred_nb, average='weighted')\n",
    "\n",
    "print(\"Precision: {:.3f}\".format(precision))\n",
    "print(\"Recall: {:.3f}\".format(recall))\n",
    "print(\"F1 Score: {:.3f}\".format(f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision (Positive Predictive Value)\n",
    "\n",
    "Definition:\n",
    "\n",
    "\n",
    "Precision = {TP}/{TP + FP}\n",
    "\n",
    "•\tMeasures how many of the predicted positive cases were actually positive.<br>\n",
    "•\tHigh Precision means fewer False Positives (FP).\n",
    "\n",
    "✅ Use case: When False Positives are costly (e.g., Spam Detection: Predicting a real email as spam is bad)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (Sensitivity or True Positive Rate)\n",
    "\n",
    "Definition:\n",
    "\n",
    "\n",
    "Recall = {TP}/{TP + FN}\n",
    "\n",
    "•\tMeasures how many actual positives were correctly predicted.<br>\n",
    "•\tHigh Recall means fewer False Negatives (FN).\n",
    "\n",
    "✅ Use case: When False Negatives are costly (e.g., Medical Diagnosis: Missing a cancer case is dangerous)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 Score (Harmonic Mean of Precision & Recall)\n",
    "\n",
    "Definition:\n",
    "\n",
    "\n",
    "F1 Score = 2 * {Precision} * {Recall}/({Precision} + {Recall})\n",
    "\n",
    "•\tBalances Precision & Recall, useful when they are unequal.<br>\n",
    "•\tHigh F1 Score indicates a good balance between False Positives and False Negatives.\n",
    "\n",
    "✅ Use case: When you need a trade-off between Precision & Recall (e.g., Fraud Detection: Avoid false alarms but still detect fraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.96      1.00      0.98       100\n",
      "           2       0.98      0.95      0.96       128\n",
      "           3       1.00      1.00      1.00       128\n",
      "           4       0.99      0.97      0.98        97\n",
      "           5       0.95      0.98      0.97       104\n",
      "\n",
      "    accuracy                           0.98       557\n",
      "   macro avg       0.98      0.98      0.98       557\n",
      "weighted avg       0.98      0.98      0.98       557\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred_nb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll try to functionalize the above code so that we can use it for a few more different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(obj):\n",
    "    obj.fit(X_train, y_train) # Training the model\n",
    "    y_pred = obj.predict(X_val) # Making predictions\n",
    "    y_pred_proba = obj.predict_proba(X_val)\n",
    "    return y_pred, y_pred_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_eval(obj, y_pred, y_pred_proba):\n",
    "    print(\"-------------------------\")\n",
    "\n",
    "    # Calculating the train & test accuracy\n",
    "    train_acc = accuracy_score(y_train, obj.predict(X_train))\n",
    "    test_acc = accuracy_score(y_val, obj.predict(X_val))\n",
    "\n",
    "    print(\"Train Accuracy: {:.3f}\".format(train_acc))\n",
    "    print(\"Test Accuracy: {:.3f}\\n\".format(test_acc))\n",
    "\n",
    "    # Computing the ROC AUC score\n",
    "    print(\"ROC AUC Score: {:.3f}\\n\".format(roc_auc_score(y_val, y_pred_proba, multi_class='ovr')))\n",
    "\n",
    "    # Computing the precision, recall & f1 score\n",
    "    precision = precision_score(y_val, y_pred, average='weighted')\n",
    "    recall = recall_score(y_val, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_val, y_pred, average='weighted')\n",
    "\n",
    "    print(\"Precision: {:.3f}\".format(precision))\n",
    "    print(\"Recall: {:.3f}\".format(recall))\n",
    "    print(\"F1 Score: {:.3f}\".format(f1))\n",
    "\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Train Accuracy: 1.000\n",
      "Test Accuracy: 0.842\n",
      "\n",
      "ROC AUC Score: 0.900\n",
      "\n",
      "Precision: 0.842\n",
      "Recall: 0.842\n",
      "F1 Score: 0.842\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_dt=DecisionTreeClassifier()\n",
    "\n",
    "# Training the model -\n",
    "y_pred_dt, y_pred_proba_dt = model_train(model_dt)\n",
    "\n",
    "# Evaluating the model -\n",
    "model_eval(model_dt, y_pred_dt, y_pred_proba_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Train Accuracy: 0.824\n",
      "Test Accuracy: 0.724\n",
      "\n",
      "ROC AUC Score: 0.933\n",
      "\n",
      "Precision: 0.824\n",
      "Recall: 0.724\n",
      "F1 Score: 0.720\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_knn= KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# Training the model -\n",
    "y_pred_knn, y_pred_proba_knn = model_train(model_knn)\n",
    "\n",
    "# Evaluating the model -\n",
    "model_eval(model_knn, y_pred_knn, y_pred_proba_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------\n",
      "Train Accuracy: 1.000\n",
      "Test Accuracy: 0.961\n",
      "\n",
      "ROC AUC Score: 0.997\n",
      "\n",
      "Precision: 0.960\n",
      "Recall: 0.961\n",
      "F1 Score: 0.960\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "model_rf=RandomForestClassifier()\n",
    "\n",
    "# Training the model -\n",
    "y_pred_rf, y_pred_proba_rf = model_train(model_rf)\n",
    "\n",
    "# Evaluating the model -\n",
    "model_eval(model_rf, y_pred_rf, y_pred_proba_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tHigh train accuracy (≈100%) + Low test accuracy → Overfitting<br>\n",
    "•\tBoth train & test accuracies are similar → Good generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Observation: Out of all the models tested till now, Naive Bayes Classifier seems to be the best performing one since it gives good train & test accuracy, more than satisfactory precision & recall and almost non-significant overfitting.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
